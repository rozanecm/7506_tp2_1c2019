{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will allow you to see all column names & rows when you are doing .head(). None of the column name will be truncated.\n",
    "# source: https://stackoverflow.com/questions/49188960/how-to-show-all-of-columns-name-on-pandas-dataframe\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_competencia_ids.csv\t\t\t\t\t\t0.200915\n",
      "zips\t\t\t\t\t\t0.004096\n",
      "clicks.csv\t\t\t\t\t\t16.147446\n",
      "auctions.csv\t\t\t\t\t\t2412.11824\n",
      "installs.csv\t\t\t\t\t\t123.502317\n",
      "events.csv\t\t\t\t\t\t2252.988966\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('../data/'):\n",
    "    print(file + '\\t\\t\\t\\t\\t\\t' + str(os.stat(\"../data/\" + file).st_size/1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "# days to consider\n",
    "all_days = [18,19,20,21,22,23,24,25,26]\n",
    "\n",
    "secs_in_3_days = 3*24*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_3_days(n):\n",
    "    \"\"\"\n",
    "    get nth block of 3 consecutive days\n",
    "    n can go from 1 to 7.\n",
    "    If n == 8, then last two days are given.\n",
    "    If n == 9, then last day is given.\n",
    "    \"\"\"\n",
    "    n -= 1\n",
    "    return all_days[n:n+3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "# load target\n",
    "def load_target():\n",
    "    target = pd.read_csv('../data/target_competencia_ids.csv')\n",
    "\n",
    "    # to avoid misunderstandings with data when predicting, and avoid accidentally predicting value zero\n",
    "#     target.obj = np.nan\n",
    "    \n",
    "    return target\n",
    "\n",
    "# para que quede cargado desde el principio\n",
    "target = load_target()\n",
    "\n",
    "# target ids related\n",
    "def get_target_ids():\n",
    "    \"\"\" get all target ids \"\"\"\n",
    "    return target['ref_hash'].apply(lambda x: x[:-3]).unique()\n",
    "\n",
    "def get_target_ids_chunk(chunk_num):\n",
    "    \"\"\" chunk num can go from 1 to 41 \"\"\"\n",
    "    chunk_size = 100\n",
    "    start = (chunk_num - 1) * chunk_size\n",
    "    stop = chunk_size * chunk_num\n",
    "    return get_target_ids()[start:stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "# para guardar predicciones\n",
    "import time\n",
    "def _get_filename(my_name, timestamp):\n",
    "    return \"../predictions/\" + timestamp + \" by \" + my_name + \".csv\"\n",
    "\n",
    "def _save_description(authors_name, timestamp, submission_description):\n",
    "    f = open(\"../predictions/\" + authors_name + \".txt\",\"a\")\n",
    "    f.write(timestamp + \": \" + submission_description + '\\n')\n",
    "    f.close()\n",
    "\n",
    "def save_submission(submission_df, authors_name=\"fabri\", description = \"no description\"):\n",
    "    timestamp = time.strftime(\"%Y.%m.%d - %H:%M:%S\")\n",
    "    submission_df.to_csv(_get_filename(authors_name, timestamp), index=False)\n",
    "    _save_description(authors_name, timestamp, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_predictions(target_df, new_values, value_column_name, suffix):\n",
    "    \"\"\"\n",
    "    adds predictions from value_column_name from new_values df\n",
    "    to target_df merging by ref_hash and the given suffix \n",
    "    suffix: \"_st\" for auction prediction\n",
    "            \"_sc\" for conversion prediction\n",
    "    \"\"\"\n",
    "    new_values['ref_hash'] = new_values['ref_hash'] + suffix\n",
    "    \n",
    "    target_df = target_df.merge(new_values[['ref_hash',value_column_name]], how='left', on='ref_hash')\n",
    "    \n",
    "    target_df.fillna(0, inplace=True)\n",
    "    \n",
    "#     assign values to 'obj' column and remove the column added on merge.\n",
    "#     after sum, fillna is needed because there are values which are left as NaNs.\n",
    "    target_df['obj'] = target_df['obj'] + target_df[value_column_name]\n",
    "    \n",
    "    target_df.drop([value_column_name], axis='columns', inplace=True)\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "# play a sound\n",
    "import os\n",
    "def ring(duration = 1, freq = 1500):\n",
    "    \"\"\" play tone of duration in seconds and freq in Hz. \"\"\"\n",
    "    os.system('play --no-show-progress --null --channels 1 synth %s sine %f' % (duration, freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_source_col(df, source):\n",
    "    \"\"\"\n",
    "    for a given dataframe, create a column indicating\n",
    "    from which csv file it originated\n",
    "    \"\"\"\n",
    "    df['source_csv'] = source\n",
    "\n",
    "    \n",
    "def process_time_diffs(df):\n",
    "    \"\"\"\n",
    "    create column indicating difference between two\n",
    "    consecutive registers for each device id\n",
    "    \"\"\"\n",
    "    asdf = df\n",
    "    \n",
    "    asdf = asdf.sort_values(['date'])\n",
    "    \n",
    "    asdf['diff'] = asdf.groupby(['ref_hash'])['date'].diff()\n",
    "\n",
    "    asdf['diff'].fillna(value=asdf['date']-asdf['date'].dt.floor('d'), inplace=True)\n",
    "\n",
    "    asdf['diff_in_sec'] = asdf['diff'].dt.total_seconds()\n",
    "\n",
    "    asdf.drop('diff', axis='columns', inplace=True)\n",
    "    \n",
    "    return asdf\n",
    "\n",
    "\n",
    "def process_time_diffs_vs_min_day(df):\n",
    "    \"\"\"\n",
    "    create column indicating difference between\n",
    "    time in registers and min day in df\n",
    "    \"\"\"\n",
    "    asdf = df\n",
    "\n",
    "    min_timestamp = asdf['date'].min().floor('d')\n",
    "\n",
    "    asdf['diff'] = asdf['date'] - min_timestamp\n",
    "\n",
    "    asdf['diff_in_sec'] = asdf['diff'].dt.total_seconds()\n",
    "\n",
    "    asdf.drop('diff', axis='columns', inplace=True)\n",
    "    \n",
    "    return asdf\n",
    "\n",
    "def is_source_that_defines_death(data, source_that_defines_death):\n",
    "    return data == source_that_defines_death\n",
    "\n",
    "def set_observed_column(df, csv_source_that_defines_death):\n",
    "    \"\"\"\n",
    "    create column indicating if death has been observed or not.\n",
    "    \"\"\"\n",
    "    asdf = df\n",
    "    \n",
    "    asdf['observed'] = asdf.source_csv.apply(lambda x: is_source_that_defines_death(x,csv_source_that_defines_death))\n",
    "    \n",
    "    return asdf\n",
    "\n",
    "\n",
    "def fill_with_mode(x):\n",
    "    \"\"\"\n",
    "    If there is any value present in group, fill nans with the mode of the group. \n",
    "    If there are all nans, leave them all as nans.\n",
    "    \"\"\"\n",
    "    if x.isnull().all():\n",
    "        return np.nan\n",
    "    else:\n",
    "        mode = x.mode()[0]\n",
    "        return x.fillna(mode)\n",
    "\n",
    "    \n",
    "def fill_nans(df):\n",
    "    \"\"\" Fill nan spaces with the mode of the group by ref_hash. \"\"\"\n",
    "    nans_filled = df\n",
    "    nans_filled = nans_filled.sort_values(by=['ref_hash','date'])\n",
    "\n",
    "    asdf = nans_filled.groupby('ref_hash', as_index=False, sort=False).transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "    asdf['ref_hash'] = nans_filled['ref_hash']\n",
    "    \n",
    "    return asdf\n",
    "\n",
    "#     nans_filled = df.groupby('ref_hash', as_index=False, sort=False).transform(lambda x: x.ffill().bfill())\n",
    "    \n",
    "#     for col in nans_filled.columns:\n",
    "#         print(\"filling column \" + col)\n",
    "# #         col_mode = nans_filled[col].mode()[0]\n",
    "#         nans_filled[col].fillna(col_mode, inplace=True)\n",
    "    \n",
    "#     nans_filled['ref_hash'] = df['ref_hash']\n",
    "#     return nans_filled\n",
    "\n",
    "# def fill_all_nans_but_diff_in_sec(df):\n",
    "#     nans_filled = fill_all_nans(df.drop(['diff_in_sec'],axis='columns'))\n",
    "#     nans_filled['diff_in_sec'] = df['diff_in_sec']\n",
    "#     return nans_filled\n",
    "\n",
    "# def object_to_categorical(df):\n",
    "#     \"\"\"\n",
    "#     Transform all 'object' dtypes to 'category'.\n",
    "#     The following answers helped address the issue:\n",
    "#         - https://stackoverflow.com/a/46762926\n",
    "#         - https://stackoverflow.com/a/39092877\n",
    "#     \"\"\"\n",
    "#     asdf = df\n",
    "    \n",
    "#     for col in asdf.columns:\n",
    "#         if asdf[col].dtype.kind == 'O':\n",
    "#             print(col)\n",
    "#             asdf[col] = asdf[col].astype('category')\n",
    "        \n",
    "#     return asdf\n",
    "\n",
    "def col_to_bool(df, cols):\n",
    "    asdf = df\n",
    "    for col in cols:\n",
    "        asdf[col] = asdf[col].astype('bool')\n",
    "    return df\n",
    "\n",
    "def get_time_to_event_of_interest(df, source_of_interest):\n",
    "    asdf = df\n",
    "    \n",
    "    asdf = asdf.sort_values(['ref_hash','date'])\n",
    "\n",
    "    asdf['timestamp_of_next_occurrence'] = asdf['date']\n",
    "    asdf.loc[asdf['source_csv'] != source_of_interest, 'timestamp_of_next_occurrence'] = np.nan\n",
    "\n",
    "    # asdf = nans_filled.groupby('ref_hash', as_index=False, sort=False).transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "    asdf['timestamp_of_next_occurrence'] = asdf['timestamp_of_next_occurrence'].bfill().ffill()\n",
    "\n",
    "    asdf['diff_in_sec'] = asdf['date']-asdf['timestamp_of_next_occurrence']\n",
    "    \n",
    "    asdf['diff_in_sec'] = asdf['diff_in_sec'].dt.total_seconds()\n",
    "\n",
    "    asdf['diff_in_sec'] = asdf['diff_in_sec'].apply(lambda x: x if x <= secs_in_3_days else secs_in_3_days)\n",
    "    asdf['diff_in_sec'] = asdf['diff_in_sec'].apply(lambda x: x if x > 0 else secs_in_3_days)\n",
    "    \n",
    "    asdf = asdf.drop('timestamp_of_next_occurrence', axis='columns')\n",
    "    \n",
    "    return asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dfs loading functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de appendear los 4 dfs y rellenar los nans con la moda por cada grupo, se ha observado, con una muestra de device ids (ref_hashes), la siguiente proporcion de nans:\n",
    "\n",
    "> source_id has 0.0% of nans.<br>\n",
    "date has 0.0% of nans.<br>\n",
    "latitude has 68.65% of nans.<br>\n",
    "longitude has 68.65% of nans.<br>\n",
    "wifi_connection has 68.65% of nans.<br>\n",
    "carrier_id has 68.65% of nans.<br>\n",
    "os_minor has 68.65% of nans.<br>\n",
    "os_major has 68.65% of nans.<br>\n",
    "specs_brand has 68.65% of nans.<br>\n",
    "timeToClick has 68.65% of nans.<br>\n",
    "touchX has 68.65% of nans.<br>\n",
    "touchY has 68.65% of nans.<br>\n",
    "ref_type has 68.65% of nans.<br>\n",
    "diff_in_sec has 0.0% of nans.<br>\n",
    "source_csv has 0.0% of nans.<br>\n",
    "application_id has 0.0% of nans.<br>\n",
    "attributed has 0.0% of nans.<br>\n",
    "implicit has 0.0% of nans.<br>\n",
    "device_brand has 34.18% of nans.<br>\n",
    "device_model has 2.14% of nans.<br>\n",
    "session_user_agent has 0.13% of nans.<br>\n",
    "device_language has 3.31% of nans.<br>\n",
    "ip_address has 16.25% of nans.<br>\n",
    "ref_type_id has 0.0% of nans.<br>\n",
    "ref_hash has 0.0% of nans.<br>\n",
    "\n",
    "Se decide no trabajar con las columnas que tengan mas de 50% de nans.\n",
    "\n",
    "Codigo ejecutado:\n",
    "```python\n",
    "for col in nans_filled.columns:\n",
    "    total_rows = nans_filled.shape[0]\n",
    "    print(str(col) + \" has \" + str(100*nans_filled[col].isna().sum()/total_rows) + \"% of nans.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "clicks_cols = ['source_id','created','ref_hash',]\n",
    "\n",
    "clicks_dtypes = {\n",
    "#     'advertiser_id':'category',\n",
    "#                  'action_id':'category',\n",
    "                 'source_id':'category',\n",
    "#                  'country_code':'category',\n",
    "#                  'latitude':'float64',\n",
    "#                  'longitude':'float64',\n",
    "#                  'wifi_connection':'bool',\n",
    "#                  'carrier_id':'category',\n",
    "#                  'trans_id':'category',\n",
    "#                  'os_minor':'category',\n",
    "#                  'agent_device':'category',\n",
    "#                  'os_major':'category',\n",
    "#                  'specs_brand':'category',\n",
    "#                  'brand':'category',\n",
    "#                  'timeToClick':'float64',\n",
    "#                  'touchX':'object',\n",
    "#                  'touchY':'object',\n",
    "#                  'ref_type':'category',\n",
    "                 'ref_hash':'category'}\n",
    "\n",
    "def load_clicks(users=get_target_ids(), days=all_days):\n",
    "    \"\"\"\n",
    "    load clicks csv, only users and days specified in users and days lists.\n",
    "    If lists left empty, consider whole set of users and days respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_clicks = pd.read_csv('../data/clicks.csv', engine='c', dtype=clicks_dtypes, parse_dates=['created'], usecols=clicks_cols)\n",
    "    \n",
    "    def load_condition(chunk):\n",
    "        return chunk['ref_hash'].isin(users) & chunk['created'].dt.day.isin(days)\n",
    "    \n",
    "    df = df_clicks.loc[load_condition(df_clicks)].copy()\n",
    "    \n",
    "    df.rename(columns={'created':'date'}, inplace=True)\n",
    "    \n",
    "    df['date'] = df['date'].dt.tz_localize(None)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "installs_cols = ['created','application_id','ref_hash','attributed','implicit','device_brand','device_model','session_user_agent','device_language']\n",
    "\n",
    "installs_dtypes = {\"application_id\":          \"category\",\n",
    "#                    \"ref_type\":                \"category\",\n",
    "                   \"ref_hash\":                \"object\",\n",
    "#                    \"click_hash\":             \"category\",\n",
    "                   \"attributed\":               \"bool\",\n",
    "                   \"implicit\":                 \"bool\",\n",
    "#                    \"device_countrycode\":      \"category\",\n",
    "                   \"device_brand\":          \"category\",\n",
    "                   \"device_model\":          \"category\",\n",
    "                   \"session_user_agent\":     \"category\",\n",
    "#                    \"user_agent\":             \"category\",\n",
    "#                    \"event_uuid\":             \"category\",\n",
    "#                    \"kind\":                   \"category\",\n",
    "#                    \"wifi\":                   \"category\",\n",
    "#                    \"trans_id\":               \"category\",\n",
    "#                    \"ip_address\":              \"category\",\n",
    "                   \"device_language\":       \"category\"}\n",
    "\n",
    "def load_installs(users=get_target_ids(), days=all_days):\n",
    "    \"\"\"\n",
    "    load installs csv, only users and days specified in users and days lists.\n",
    "    If lists left empty, consider whole set of users and days respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_installs = pd.read_csv('../data/installs.csv', engine='c', dtype=installs_dtypes, parse_dates=['created'], usecols=installs_cols)\n",
    "    \n",
    "    def load_condition(df):\n",
    "        return df['ref_hash'].isin(users) & df['created'].dt.day.isin(days)\n",
    "    \n",
    "    df = df_installs.loc[load_condition(df_installs)].copy()\n",
    "    \n",
    "    df.rename(columns={'created':'date'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "events_cols = ['date','ref_hash','application_id','attributed','device_model','ip_address']\n",
    "\n",
    "events_dtypes = {\n",
    "#     \"index\":                   \"category\",\n",
    "#                  \"event_id\":                \"category\",\n",
    "#                  \"ref_type\":                \"category\",\n",
    "                 \"ref_hash\":                \"category\",\n",
    "                 \"application_id\":          \"category\",\n",
    "                 \"attributed\":               \"bool\",\n",
    "#                  \"device_countrycode\":      \"category\",\n",
    "#                  \"device_os_version\":     \"category\",\n",
    "#                  \"device_brand\":          \"category\",\n",
    "                 \"device_model\":          \"category\",\n",
    "#                  \"device_city\":           \"category\",\n",
    "#                  \"session_user_agent\":    \"category\",\n",
    "#                  \"trans_id\":               \"category\",\n",
    "#                  \"user_agent\":            \"category\",\n",
    "#                  \"event_uuid\":             \"category\",\n",
    "#                  \"carrier\":               \"category\",\n",
    "#                  \"kind\":                  \"category\",\n",
    "#                  \"device_os\":             \"category\",\n",
    "#                  \"wifi\":                     \"bool\",\n",
    "#                  \"connection_type\":        \"category\",\n",
    "                 \"ip_address\":              \"category\",\n",
    "#                  \"device_language\":       \"category\"\n",
    "}\n",
    "\n",
    "def load_events(users=get_target_ids(), days=all_days):\n",
    "    \"\"\"\n",
    "    load events csv, only users and days specified in users and days lists.\n",
    "    If lists left empty, consider whole set of users and days respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    iter_events = pd.read_csv('../data/events.csv', engine='c', dtype=events_dtypes, parse_dates=['date'], chunksize=10000, usecols=events_cols)\n",
    "    \n",
    "    def load_condition(chunk):\n",
    "        return chunk['ref_hash'].isin(users) & chunk['date'].dt.day.isin(days)\n",
    "    \n",
    "    df = pd.concat(chunk.loc[load_condition(chunk)] for chunk in iter_events)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "auction_cols = ['date','device_id']\n",
    "\n",
    "auctions_dtypes = {'device_id':'category',\n",
    "#                  'ref_type_id':'category',\n",
    "#                  'source_id':'category'\n",
    "                  }\n",
    "\n",
    "def load_auctions(users=get_target_ids(), days=all_days):\n",
    "    \"\"\"\n",
    "    load auctions csv, only users and days specified in users and days lists.\n",
    "    If lists left empty, consider whole set of users and days respectively.\n",
    "    \"\"\"\n",
    "    iter_auctions = pd.read_csv('../data/auctions.csv', engine='c', dtype=auctions_dtypes, parse_dates=['date'], chunksize=10000, usecols=auction_cols)\n",
    "    def load_condition(chunk):\n",
    "        return chunk['device_id'].isin(users) & chunk['date'].dt.day.isin(days)\n",
    "    df = pd.concat(chunk.loc[load_condition(chunk)] for chunk in iter_auctions)\n",
    "    \n",
    "    df.rename(columns={'device_id':'ref_hash'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudo resumen de cosas utiles para aplicar\n",
    "Para survival analysis se necesitan dos cosas:\n",
    "- an array of durations\n",
    "- either a boolean or binary array representing whether the “death” was observed or not (alternatively an individual can be censored)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML: Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Approach 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_users = get_target_ids()\n",
    "current_days = get_n_3_days(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = load_clicks(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = load_events(current_users, current_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = process_time_diffs(df_auctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = df_auctions2.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_auctions2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions.to_csv('df_auctions_window_1.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_days = get_n_3_days(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = process_time_diffs(df_auctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = df_auctions2.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_auctions2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions.to_csv('df_auctions_window_2.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_days = get_n_3_days(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = process_time_diffs(df_auctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = df_auctions2.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_auctions2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions.to_csv('df_auctions_window_3.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_days = get_n_3_days(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = process_time_diffs(df_auctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = df_auctions2.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_auctions2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions.to_csv('df_auctions_window_4.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_days = get_n_3_days(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = process_time_diffs(df_auctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = df_auctions2.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_auctions2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions.to_csv('df_auctions_window_5.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_days = get_n_3_days(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = process_time_diffs(df_auctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = df_auctions2.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_auctions2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions.to_csv('df_auctions_window_6.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_auctions2\n",
    "del df_auctions\n",
    "del current_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_window_1 = pd.read_csv('df_auctions_window_1.csv')\n",
    "auction_window_2 = pd.read_csv('df_auctions_window_2.csv')\n",
    "auction_window_3 = pd.read_csv('df_auctions_window_3.csv')\n",
    "auction_window_4 = pd.read_csv('df_auctions_window_4.csv')\n",
    "auction_window_5 = pd.read_csv('df_auctions_window_5.csv')\n",
    "auction_window_6 = pd.read_csv('df_auctions_window_6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = auction_window_1.iloc[:,:-1],auction_window_1.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = auction_window_2.iloc[:,:-1],auction_window_2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo datos numericos\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 12,\n",
    "                missing=-999, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=-999, n_estimators=12,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 21976.192765\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = auction_window_2.iloc[:,:-1],auction_window_2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = auction_window_3.iloc[:,:-1],auction_window_3.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo datos numericos\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 12,\n",
    "                missing=-999, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=-999, n_estimators=12,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22293.294801\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = auction_window_3.iloc[:,:-1],auction_window_3.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = auction_window_4.iloc[:,:-1],auction_window_4.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo datos numericos\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 12,\n",
    "                missing=-999, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=-999, n_estimators=12,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22568.301623\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window 4 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = auction_window_4.iloc[:,:-1],auction_window_4.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = auction_window_5.iloc[:,:-1],auction_window_5.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo datos numericos\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 12,\n",
    "                missing=-999, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=-999, n_estimators=12,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 23252.154421\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = auction_window_5.iloc[:,:-1],auction_window_5.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = auction_window_6.iloc[:,:-1],auction_window_6.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo datos numericos\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 12,\n",
    "                missing=-999, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=-999, n_estimators=12,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22873.055770\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_st = target[target['ref_hash'].str.endswith('_st')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabrizio/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "targets_st['ref_hash'] = targets_st['ref_hash'].str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabrizio/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "targets_st['ref_hash'] = targets_st['ref_hash'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de archivos CSV\n",
    "dfAuctions = pd.read_csv('../data/auctions.csv', \n",
    "                 engine='c', \n",
    "                 usecols=['device_id','ref_type_id', 'source_id'], \n",
    "                 dtype={'ref_type_id':np.int8, 'source_id':np.int8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAuctions = dfAuctions.drop_duplicates(subset = 'device_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_st.columns = ['device_id','obj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_st = targets_st.merge(dfAuctions[['device_id']], on = 'device_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_st.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_st = targets_st.drop(columns = ['obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_st.columns = ['ref_hash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = auction_window_6.iloc[:,:-1],auction_window_6.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo datos numericos\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 12,\n",
    "                missing=-999, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=-999, n_estimators=12,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_st = xg_reg.predict(targets_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabrizio/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "target_preds_st = target[target['ref_hash'].str.contains('_st')]\n",
    "target_preds_st['obj'] = preds_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_auctions\n",
    "del df_auctions2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_users = get_target_ids()\n",
    "current_days = get_n_3_days(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs = load_installs(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs2 = process_time_diffs(df_installs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs2 = df_installs2.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_installs2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions.to_csv('df_installs_window_1.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_days = get_n_3_days(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs = load_installs(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs2 = process_time_diffs(df_installs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs2 = df_installs2.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_installs2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions.to_csv('df_installs_window_2.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_days = get_n_3_days(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs = load_installs(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs2 = process_time_diffs(df_installs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs2 = df_installs2.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_installs2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions.to_csv('df_installs_window_3.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_days = get_n_3_days(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs = load_installs(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs2 = process_time_diffs(df_installs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs2 = df_installs2.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_installs2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions.to_csv('df_installs_window_4.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_days = get_n_3_days(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs = load_installs(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs2 = process_time_diffs(df_installs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs2 = df_installs2.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_installs2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions.to_csv('df_installs_window_5.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_days = get_n_3_days(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs = load_installs(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs2 = process_time_diffs(df_installs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs2 = df_installs2.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_installs2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions.to_csv('df_installs_window_6.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_installs2\n",
    "del df_installs\n",
    "del current_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs_window_1 = pd.read_csv('df_installs_window_1.csv')\n",
    "installs_window_2 = pd.read_csv('df_installs_window_2.csv')\n",
    "installs_window_3 = pd.read_csv('df_installs_window_3.csv')\n",
    "installs_window_4 = pd.read_csv('df_installs_window_4.csv')\n",
    "installs_window_5 = pd.read_csv('df_installs_window_5.csv')\n",
    "installs_window_6 = pd.read_csv('df_installs_window_6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = installs_window_1.iloc[:,:-1],installs_window_1.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = installs_window_2.iloc[:,:-1],installs_window_2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo datos numericos\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 12,\n",
    "                missing=-999, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=-999, n_estimators=12,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 29529.687908\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = installs_window_2.iloc[:,:-1],installs_window_2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = installs_window_3.iloc[:,:-1],installs_window_3.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo datos numericos\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 12,\n",
    "                missing=-999, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=-999, n_estimators=12,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 29967.764219\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = installs_window_3.iloc[:,:-1],installs_window_3.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = installs_window_4.iloc[:,:-1],installs_window_4.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo datos numericos\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 12,\n",
    "                missing=-999, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=-999, n_estimators=12,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 29974.186441\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window 4 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = installs_window_4.iloc[:,:-1],installs_window_4.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = installs_window_5.iloc[:,:-1],installs_window_5.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo datos numericos\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 12,\n",
    "                missing=-999, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=-999, n_estimators=12,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 30747.226603\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = installs_window_5.iloc[:,:-1],installs_window_5.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = installs_window_6.iloc[:,:-1],installs_window_6.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo datos numericos\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 12,\n",
    "                missing=-999, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=-999, n_estimators=12,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 30337.516312\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_sc = target[target['ref_hash'].str.endswith('_sc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabrizio/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "targets_sc['ref_hash'] = targets_sc['ref_hash'].str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabrizio/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "targets_sc['ref_hash'] = targets_sc['ref_hash'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de archivos CSV\n",
    "dfInstalls = pd.read_csv('../data/installs.csv',\n",
    "                 engine='c', \n",
    "                 usecols=['ref_hash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInstalls = dfInstalls.drop_duplicates(subset = 'ref_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_sc = targets_sc.merge(dfInstalls[['ref_hash']], on = 'ref_hash', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_sc.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_sc = targets_sc.drop(columns = ['obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = installs_window_6.iloc[:,:-1],installs_window_6.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo datos numericos\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 12,\n",
    "                missing=-999, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=-999, n_estimators=12,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sc = xg_reg.predict(targets_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabrizio/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "target_preds_sc = target[target['ref_hash'].str.contains('_sc')]\n",
    "target_preds_sc['obj'] = preds_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000169251625791246_sc</td>\n",
       "      <td>32630.986328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000395625957344683_sc</td>\n",
       "      <td>32630.986328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003027494996471685_sc</td>\n",
       "      <td>32630.986328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1006670001679961544_sc</td>\n",
       "      <td>32630.986328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1007573308966476713_sc</td>\n",
       "      <td>32630.986328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ref_hash           obj\n",
       "0  1000169251625791246_sc  32630.986328\n",
       "2  1000395625957344683_sc  32630.986328\n",
       "4  1003027494996471685_sc  32630.986328\n",
       "6  1006670001679961544_sc  32630.986328\n",
       "8  1007573308966476713_sc  32630.986328"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_preds_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000169251625791246_st</td>\n",
       "      <td>14093.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000395625957344683_st</td>\n",
       "      <td>14093.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1003027494996471685_st</td>\n",
       "      <td>14093.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1006670001679961544_st</td>\n",
       "      <td>14093.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1007573308966476713_st</td>\n",
       "      <td>14093.609375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ref_hash           obj\n",
       "1  1000169251625791246_st  14093.609375\n",
       "3  1000395625957344683_st  14093.609375\n",
       "5  1003027494996471685_st  14093.609375\n",
       "7  1006670001679961544_st  14093.609375\n",
       "9  1007573308966476713_st  14093.609375"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_preds_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_to_save = [target_preds_sc, target_preds_st]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_to_save = pd.concat(target_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(target_to_save, description=\"por cada grupo, avg. de los tiempos entre cada registro con xgboost.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_installs = load_installs()\n",
    "\n",
    "# df_installs2 = process_time_diffs(df_installs)\n",
    "\n",
    "# current_predictions = df_installs2[['ref_hash','diff_in_sec']].groupby('ref_hash', as_index=False).mean()\n",
    "\n",
    "# target = store_predictions(target_df=target, new_values=current_predictions, value_column_name='diff_in_sec', suffix='_sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_installs\n",
    "del df_installs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_submission(target, description=\"por cada grupo, avg. de los tiempos entre cada registro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Approach 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
