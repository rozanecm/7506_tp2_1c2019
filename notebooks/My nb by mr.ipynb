{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will allow you to see all column names & rows when you are doing .head(). None of the column name will be truncated.\n",
    "# source: https://stackoverflow.com/questions/49188960/how-to-show-all-of-columns-name-on-pandas-dataframe\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auctions.csv\t\t\t\t\t\t2412.11824\n",
      ".ipynb_checkpoints\t\t\t\t\t\t0.004096\n",
      "target_competencia_ids.csv\t\t\t\t\t\t0.200915\n",
      "installs.csv\t\t\t\t\t\t123.502317\n",
      "desc.json\t\t\t\t\t\t0.009146\n",
      "Recomendaciones y aclaraciones.docx\t\t\t\t\t\t0.006909\n",
      "clicks.csv\t\t\t\t\t\t16.147446\n",
      "events.csv\t\t\t\t\t\t2252.988966\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('../data/'):\n",
    "    print(file + '\\t\\t\\t\\t\\t\\t' + str(os.stat(\"../data/\" + file).st_size/1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "# days to consider\n",
    "all_days = [18,19,20,21,22,23,24,25,26]\n",
    "\n",
    "secs_in_3_days = 3*24*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_3_days(n):\n",
    "    \"\"\"\n",
    "    get nth block of 3 consecutive days\n",
    "    n can go from 1 to 7.\n",
    "    If n == 8, then last two days are given.\n",
    "    If n == 9, then last day is given.\n",
    "    \"\"\"\n",
    "    n -= 1\n",
    "    return all_days[n:n+3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "# load target\n",
    "def load_target():\n",
    "    target = pd.read_csv('../data/target_competencia_ids.csv')\n",
    "\n",
    "    # to avoid misunderstandings with data when predicting, and avoid accidentally predicting value zero\n",
    "#     target.obj = np.nan\n",
    "    \n",
    "    return target\n",
    "\n",
    "# para que quede cargado desde el principio\n",
    "target = load_target()\n",
    "\n",
    "# target ids related\n",
    "def get_target_ids():\n",
    "    \"\"\" get all target ids \"\"\"\n",
    "    return target['ref_hash'].apply(lambda x: x[:-3]).unique()\n",
    "\n",
    "def get_target_ids_chunk(chunk_num):\n",
    "    \"\"\" chunk num can go from 1 to 41 \"\"\"\n",
    "    chunk_size = 100\n",
    "    start = (chunk_num - 1) * chunk_size\n",
    "    stop = chunk_size * chunk_num\n",
    "    return get_target_ids()[start:stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "# para guardar predicciones\n",
    "import time\n",
    "def _get_filename(my_name, timestamp):\n",
    "    return \"../predictions/\" + timestamp + \" by \" + my_name + \".csv\"\n",
    "\n",
    "def _save_description(authors_name, timestamp, submission_description):\n",
    "    f = open(\"../predictions/\" + authors_name + \".txt\",\"a\")\n",
    "    f.write(timestamp + \": \" + submission_description + '\\n')\n",
    "    f.close()\n",
    "\n",
    "def save_submission(submission_df, authors_name=\"mati\", description = \"no description\"):\n",
    "    timestamp = time.strftime(\"%Y.%m.%d - %H:%M:%S\")\n",
    "    submission_df.to_csv(_get_filename(authors_name, timestamp), index=False)\n",
    "    _save_description(authors_name, timestamp, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_predictions(target_df, new_values, value_column_name, suffix):\n",
    "    \"\"\"\n",
    "    adds predictions from value_column_name from new_values df\n",
    "    to target_df merging by ref_hash and the given suffix \n",
    "    suffix: \"_st\" for auction prediction\n",
    "            \"_sc\" for conversion prediction\n",
    "    \"\"\"\n",
    "    new_values['ref_hash'] = new_values['ref_hash'] + suffix\n",
    "    \n",
    "    target_df = target_df.merge(new_values[['ref_hash',value_column_name]], how='left', on='ref_hash')\n",
    "    \n",
    "    target_df.fillna(0, inplace=True)\n",
    "    \n",
    "#     assign values to 'obj' column and remove the column added on merge.\n",
    "#     after sum, fillna is needed because there are values which are left as NaNs.\n",
    "    target_df['obj'] = target_df['obj'] + target_df[value_column_name]\n",
    "    \n",
    "    target_df.drop([value_column_name], axis='columns', inplace=True)\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "# play a sound\n",
    "import os\n",
    "def ring(duration = 1, freq = 1500):\n",
    "    \"\"\" play tone of duration in seconds and freq in Hz. \"\"\"\n",
    "    os.system('play --no-show-progress --null --channels 1 synth %s sine %f' % (duration, freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_source_col(df, source):\n",
    "    \"\"\"\n",
    "    for a given dataframe, create a column indicating\n",
    "    from which csv file it originated\n",
    "    \"\"\"\n",
    "    df['source_csv'] = source\n",
    "\n",
    "    \n",
    "def process_time_diffs(df):\n",
    "    \"\"\"\n",
    "    create column indicating difference between two\n",
    "    consecutive registers for each device id\n",
    "    \"\"\"\n",
    "    asdf = df\n",
    "    \n",
    "    asdf = asdf.sort_values(['date'])\n",
    "    \n",
    "    asdf['diff'] = asdf.groupby(['ref_hash'])['date'].diff()\n",
    "\n",
    "    asdf['diff'].fillna(value=asdf['date']-asdf['date'].dt.floor('d'), inplace=True)\n",
    "\n",
    "    asdf['diff_in_sec'] = asdf['diff'].dt.total_seconds()\n",
    "\n",
    "    asdf.drop('diff', axis='columns', inplace=True)\n",
    "    \n",
    "    return asdf\n",
    "\n",
    "\n",
    "def process_time_diffs_vs_min_day(df):\n",
    "    \"\"\"\n",
    "    create column indicating difference between\n",
    "    time in registers and min day in df\n",
    "    \"\"\"\n",
    "    asdf = df\n",
    "\n",
    "    min_timestamp = asdf['date'].min().floor('d')\n",
    "\n",
    "    asdf['diff'] = asdf['date'] - min_timestamp\n",
    "\n",
    "    asdf['diff_in_sec'] = asdf['diff'].dt.total_seconds()\n",
    "\n",
    "    asdf.drop('diff', axis='columns', inplace=True)\n",
    "    \n",
    "    return asdf\n",
    "\n",
    "def is_source_that_defines_death(data, source_that_defines_death):\n",
    "    return data == source_that_defines_death\n",
    "\n",
    "def set_observed_column(df, csv_source_that_defines_death):\n",
    "    \"\"\"\n",
    "    create column indicating if death has been observed or not.\n",
    "    \"\"\"\n",
    "    asdf = df\n",
    "    \n",
    "    asdf['observed'] = asdf.source_csv.apply(lambda x: is_source_that_defines_death(x,csv_source_that_defines_death))\n",
    "    \n",
    "    return asdf\n",
    "\n",
    "\n",
    "def fill_with_mode(x):\n",
    "    \"\"\"\n",
    "    If there is any value present in group, fill nans with the mode of the group. \n",
    "    If there are all nans, leave them all as nans.\n",
    "    \"\"\"\n",
    "    if x.isnull().all():\n",
    "        return np.nan\n",
    "    else:\n",
    "        mode = x.mode()[0]\n",
    "        return x.fillna(mode)\n",
    "\n",
    "    \n",
    "def fill_nans(df):\n",
    "    \"\"\" Fill nan spaces with the mode of the group by ref_hash. \"\"\"\n",
    "    nans_filled = df\n",
    "    nans_filled = nans_filled.sort_values(by=['ref_hash','date'])\n",
    "\n",
    "    asdf = nans_filled.groupby('ref_hash', as_index=False, sort=False).transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "    asdf['ref_hash'] = nans_filled['ref_hash']\n",
    "    \n",
    "    return asdf\n",
    "\n",
    "#     nans_filled = df.groupby('ref_hash', as_index=False, sort=False).transform(lambda x: x.ffill().bfill())\n",
    "    \n",
    "#     for col in nans_filled.columns:\n",
    "#         print(\"filling column \" + col)\n",
    "# #         col_mode = nans_filled[col].mode()[0]\n",
    "#         nans_filled[col].fillna(col_mode, inplace=True)\n",
    "    \n",
    "#     nans_filled['ref_hash'] = df['ref_hash']\n",
    "#     return nans_filled\n",
    "\n",
    "# def fill_all_nans_but_diff_in_sec(df):\n",
    "#     nans_filled = fill_all_nans(df.drop(['diff_in_sec'],axis='columns'))\n",
    "#     nans_filled['diff_in_sec'] = df['diff_in_sec']\n",
    "#     return nans_filled\n",
    "\n",
    "# def object_to_categorical(df):\n",
    "#     \"\"\"\n",
    "#     Transform all 'object' dtypes to 'category'.\n",
    "#     The following answers helped address the issue:\n",
    "#         - https://stackoverflow.com/a/46762926\n",
    "#         - https://stackoverflow.com/a/39092877\n",
    "#     \"\"\"\n",
    "#     asdf = df\n",
    "    \n",
    "#     for col in asdf.columns:\n",
    "#         if asdf[col].dtype.kind == 'O':\n",
    "#             print(col)\n",
    "#             asdf[col] = asdf[col].astype('category')\n",
    "        \n",
    "#     return asdf\n",
    "\n",
    "def col_to_bool(df, cols):\n",
    "    asdf = df\n",
    "    for col in cols:\n",
    "        asdf[col] = asdf[col].astype('bool')\n",
    "    return df\n",
    "\n",
    "def get_time_to_event_of_interest(df, source_of_interest):\n",
    "    asdf = df\n",
    "    \n",
    "    asdf = asdf.sort_values(['ref_hash','date'])\n",
    "\n",
    "    asdf['timestamp_of_next_occurrence'] = asdf['date']\n",
    "    asdf.loc[asdf['source_csv'] != source_of_interest, 'timestamp_of_next_occurrence'] = np.nan\n",
    "\n",
    "    # asdf = nans_filled.groupby('ref_hash', as_index=False, sort=False).transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "    asdf['timestamp_of_next_occurrence'] = asdf['timestamp_of_next_occurrence'].bfill().ffill()\n",
    "\n",
    "    asdf['diff_in_sec'] = asdf['date']-asdf['timestamp_of_next_occurrence']\n",
    "    \n",
    "    asdf['diff_in_sec'] = asdf['diff_in_sec'].dt.total_seconds()\n",
    "\n",
    "    asdf['diff_in_sec'] = asdf['diff_in_sec'].apply(lambda x: x if x <= secs_in_3_days else secs_in_3_days)\n",
    "    asdf['diff_in_sec'] = asdf['diff_in_sec'].apply(lambda x: x if x > 0 else secs_in_3_days)\n",
    "    \n",
    "    asdf = asdf.drop('timestamp_of_next_occurrence', axis='columns')\n",
    "    \n",
    "    return asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dfs loading functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de appendear los 4 dfs y rellenar los nans con la moda por cada grupo, se ha observado, con una muestra de device ids (ref_hashes), la siguiente proporcion de nans:\n",
    "\n",
    "> source_id has 0.0% of nans.<br>\n",
    "date has 0.0% of nans.<br>\n",
    "latitude has 68.65% of nans.<br>\n",
    "longitude has 68.65% of nans.<br>\n",
    "wifi_connection has 68.65% of nans.<br>\n",
    "carrier_id has 68.65% of nans.<br>\n",
    "os_minor has 68.65% of nans.<br>\n",
    "os_major has 68.65% of nans.<br>\n",
    "specs_brand has 68.65% of nans.<br>\n",
    "timeToClick has 68.65% of nans.<br>\n",
    "touchX has 68.65% of nans.<br>\n",
    "touchY has 68.65% of nans.<br>\n",
    "ref_type has 68.65% of nans.<br>\n",
    "diff_in_sec has 0.0% of nans.<br>\n",
    "source_csv has 0.0% of nans.<br>\n",
    "application_id has 0.0% of nans.<br>\n",
    "attributed has 0.0% of nans.<br>\n",
    "implicit has 0.0% of nans.<br>\n",
    "device_brand has 34.18% of nans.<br>\n",
    "device_model has 2.14% of nans.<br>\n",
    "session_user_agent has 0.13% of nans.<br>\n",
    "device_language has 3.31% of nans.<br>\n",
    "ip_address has 16.25% of nans.<br>\n",
    "ref_type_id has 0.0% of nans.<br>\n",
    "ref_hash has 0.0% of nans.<br>\n",
    "\n",
    "Se decide no trabajar con las columnas que tengan mas de 50% de nans.\n",
    "\n",
    "Codigo ejecutado:\n",
    "```python\n",
    "for col in nans_filled.columns:\n",
    "    total_rows = nans_filled.shape[0]\n",
    "    print(str(col) + \" has \" + str(100*nans_filled[col].isna().sum()/total_rows) + \"% of nans.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "clicks_cols = ['source_id','latitude','longitude','wifi_connection','brand','timeToClick','touchX','touchY','created','ref_hash',]\n",
    "\n",
    "clicks_dtypes = {\n",
    "#     'advertiser_id':'category',\n",
    "#                  'action_id':'category',\n",
    "                 'source_id':'category',\n",
    "#                  'country_code':'category',\n",
    "                 'latitude':'float64',\n",
    "                 'longitude':'float64',\n",
    "                 'wifi_connection':'bool',\n",
    "#                  'carrier_id':'category',\n",
    "#                  'trans_id':'category',\n",
    "#                  'os_minor':'category',\n",
    "#                  'agent_device':'category',\n",
    "#                  'os_major':'category',\n",
    "#                  'specs_brand':'category',\n",
    "                 'brand':'category',\n",
    "                 'timeToClick':'float64',\n",
    "                 'touchX':'object',\n",
    "                 'touchY':'object',\n",
    "#                  'ref_type':'category',\n",
    "                 'ref_hash':'category'}\n",
    "\n",
    "def load_clicks(users=get_target_ids(), days=all_days):\n",
    "    \"\"\"\n",
    "    load clicks csv, only users and days specified in users and days lists.\n",
    "    If lists left empty, consider whole set of users and days respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_clicks = pd.read_csv('../data/clicks.csv', engine='c', dtype=clicks_dtypes, parse_dates=['created'], usecols=clicks_cols)\n",
    "    \n",
    "    def load_condition(chunk):\n",
    "        return chunk['ref_hash'].isin(users) & chunk['created'].dt.day.isin(days)\n",
    "    \n",
    "    df = df_clicks.loc[load_condition(df_clicks)].copy()\n",
    "    \n",
    "    df.rename(columns={'created':'date'}, inplace=True)\n",
    "    \n",
    "    df['date'] = df['date'].dt.tz_localize(None)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "installs_cols = ['created','application_id','ref_hash','attributed','implicit','device_brand','device_model','session_user_agent','device_language']\n",
    "\n",
    "installs_dtypes = {\"application_id\":          \"category\",\n",
    "#                    \"ref_type\":                \"category\",\n",
    "                   \"ref_hash\":                \"object\",\n",
    "#                    \"click_hash\":             \"category\",\n",
    "                   \"attributed\":               \"bool\",\n",
    "                   \"implicit\":                 \"bool\",\n",
    "#                    \"device_countrycode\":      \"category\",\n",
    "                   \"device_brand\":          \"category\",\n",
    "                   \"device_model\":          \"category\",\n",
    "                   \"session_user_agent\":     \"category\",\n",
    "#                    \"user_agent\":             \"category\",\n",
    "#                    \"event_uuid\":             \"category\",\n",
    "#                    \"kind\":                   \"category\",\n",
    "#                    \"wifi\":                   \"category\",\n",
    "#                    \"trans_id\":               \"category\",\n",
    "#                    \"ip_address\":              \"category\",\n",
    "                   \"device_language\":       \"category\"}\n",
    "\n",
    "def load_installs(users=get_target_ids(), days=all_days):\n",
    "    \"\"\"\n",
    "    load installs csv, only users and days specified in users and days lists.\n",
    "    If lists left empty, consider whole set of users and days respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_installs = pd.read_csv('../data/installs.csv', engine='c', dtype=installs_dtypes, parse_dates=['created'], usecols=installs_cols)\n",
    "    \n",
    "    def load_condition(df):\n",
    "        return df['ref_hash'].isin(users) & df['created'].dt.day.isin(days)\n",
    "    \n",
    "    df = df_installs.loc[load_condition(df_installs)].copy()\n",
    "    \n",
    "    df.rename(columns={'created':'date'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "events_cols = ['date','ref_hash','application_id','attributed','device_model','ip_address']\n",
    "\n",
    "events_dtypes = {\n",
    "#     \"index\":                   \"category\",\n",
    "#                  \"event_id\":                \"category\",\n",
    "#                  \"ref_type\":                \"category\",\n",
    "                 \"ref_hash\":                \"category\",\n",
    "                 \"application_id\":          \"category\",\n",
    "                 \"attributed\":               \"bool\",\n",
    "#                  \"device_countrycode\":      \"category\",\n",
    "#                  \"device_os_version\":     \"category\",\n",
    "#                  \"device_brand\":          \"category\",\n",
    "                 \"device_model\":          \"category\",\n",
    "#                  \"device_city\":           \"category\",\n",
    "#                  \"session_user_agent\":    \"category\",\n",
    "#                  \"trans_id\":               \"category\",\n",
    "#                  \"user_agent\":            \"category\",\n",
    "#                  \"event_uuid\":             \"category\",\n",
    "#                  \"carrier\":               \"category\",\n",
    "#                  \"kind\":                  \"category\",\n",
    "#                  \"device_os\":             \"category\",\n",
    "#                  \"wifi\":                     \"bool\",\n",
    "#                  \"connection_type\":        \"category\",\n",
    "                 \"ip_address\":              \"category\",\n",
    "#                  \"device_language\":       \"category\"\n",
    "}\n",
    "\n",
    "def load_events(users=get_target_ids(), days=all_days):\n",
    "    \"\"\"\n",
    "    load events csv, only users and days specified in users and days lists.\n",
    "    If lists left empty, consider whole set of users and days respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    iter_events = pd.read_csv('../data/events.csv', engine='c', dtype=events_dtypes, parse_dates=['date'], chunksize=10000, usecols=events_cols)\n",
    "    \n",
    "    def load_condition(chunk):\n",
    "        return chunk['ref_hash'].isin(users) & chunk['date'].dt.day.isin(days)\n",
    "    \n",
    "    df = pd.concat(chunk.loc[load_condition(chunk)] for chunk in iter_events)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "auction_cols = ['date','device_id']\n",
    "\n",
    "auctions_dtypes = {'device_id':'category',\n",
    "#                  'ref_type_id':'category',\n",
    "#                  'source_id':'category'\n",
    "                  }\n",
    "\n",
    "def load_auctions(users=get_target_ids(), days=all_days):\n",
    "    \"\"\"\n",
    "    load auctions csv, only users and days specified in users and days lists.\n",
    "    If lists left empty, consider whole set of users and days respectively.\n",
    "    \"\"\"\n",
    "    iter_auctions = pd.read_csv('../data/auctions.csv', engine='c', dtype=auctions_dtypes, parse_dates=['date'], chunksize=10000, usecols=auction_cols)\n",
    "    def load_condition(chunk):\n",
    "        return chunk['device_id'].isin(users) & chunk['date'].dt.day.isin(days)\n",
    "    df = pd.concat(chunk.loc[load_condition(chunk)] for chunk in iter_auctions)\n",
    "    \n",
    "    df.rename(columns={'device_id':'ref_hash'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudo resumen de cosas utiles para aplicar\n",
    "Para survival analysis se necesitan dos cosas:\n",
    "- an array of durations\n",
    "- either a boolean or binary array representing whether the “death” was observed or not (alternatively an individual can be censored)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un vistazo sobre los dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_clicks(get_target_ids_chunk(1), all_days[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>date</th>\n",
       "      <th>ref_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11899</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-20 04:23:39.214</td>\n",
       "      <td>1102680423242413676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11922</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-20 04:30:28.785</td>\n",
       "      <td>1102680423242413676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25085</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 16:55:31.227</td>\n",
       "      <td>1102680423242413676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61291</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-20 19:53:18.984</td>\n",
       "      <td>1058525390691423513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63806</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-19 12:46:43.763</td>\n",
       "      <td>1058525390691423513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_id                    date             ref_hash\n",
       "11899         1 2019-04-20 04:23:39.214  1102680423242413676\n",
       "11922         1 2019-04-20 04:30:28.785  1102680423242413676\n",
       "25085         1 2019-04-18 16:55:31.227  1102680423242413676\n",
       "61291         1 2019-04-20 19:53:18.984  1058525390691423513\n",
       "63806         1 2019-04-19 12:46:43.763  1058525390691423513"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_installs(get_target_ids_chunk(1), all_days[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>application_id</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>attributed</th>\n",
       "      <th>implicit</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>session_user_agent</th>\n",
       "      <th>device_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7016</th>\n",
       "      <td>2019-04-19 02:37:34.033</td>\n",
       "      <td>14</td>\n",
       "      <td>1128814228344083814</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.208834667126999e+18</td>\n",
       "      <td>4.445013666528814e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3013777759776993e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>2019-04-19 02:37:34.101</td>\n",
       "      <td>14</td>\n",
       "      <td>1128814228344083814</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.208834667126999e+18</td>\n",
       "      <td>4.445013666528814e+18</td>\n",
       "      <td>HasOffers Mobile AppTracking v1.0</td>\n",
       "      <td>3.3013777759776993e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28381</th>\n",
       "      <td>2019-04-18 22:23:29.656</td>\n",
       "      <td>49</td>\n",
       "      <td>1048782984015604883</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.794880020077885e+18</td>\n",
       "      <td>http-kit/2.0</td>\n",
       "      <td>8.441417429938962e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48676</th>\n",
       "      <td>2019-04-20 12:35:20.625</td>\n",
       "      <td>77</td>\n",
       "      <td>1054881396892383323</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3445980799392305e+18</td>\n",
       "      <td>adjust.com</td>\n",
       "      <td>4.060929664968129e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50673</th>\n",
       "      <td>2019-04-20 02:31:26.269</td>\n",
       "      <td>78</td>\n",
       "      <td>1010265377387765028</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.115025880051902e+18</td>\n",
       "      <td>1.670346184923358e+18</td>\n",
       "      <td>http-kit/2.0</td>\n",
       "      <td>6.977049253562486e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date application_id             ref_hash  attributed  \\\n",
       "7016  2019-04-19 02:37:34.033             14  1128814228344083814       False   \n",
       "7022  2019-04-19 02:37:34.101             14  1128814228344083814       False   \n",
       "28381 2019-04-18 22:23:29.656             49  1048782984015604883       False   \n",
       "48676 2019-04-20 12:35:20.625             77  1054881396892383323       False   \n",
       "50673 2019-04-20 02:31:26.269             78  1010265377387765028       False   \n",
       "\n",
       "       implicit           device_brand            device_model  \\\n",
       "7016      False  2.208834667126999e+18   4.445013666528814e+18   \n",
       "7022       True  2.208834667126999e+18   4.445013666528814e+18   \n",
       "28381      True                    NaN   6.794880020077885e+18   \n",
       "48676     False                    NaN  1.3445980799392305e+18   \n",
       "50673     False  6.115025880051902e+18   1.670346184923358e+18   \n",
       "\n",
       "                      session_user_agent         device_language  \n",
       "7016                                 NaN  3.3013777759776993e+18  \n",
       "7022   HasOffers Mobile AppTracking v1.0  3.3013777759776993e+18  \n",
       "28381                       http-kit/2.0   8.441417429938962e+18  \n",
       "48676                         adjust.com   4.060929664968129e+18  \n",
       "50673                       http-kit/2.0   6.977049253562486e+18  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_events(get_target_ids_chunk(1), all_days[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>application_id</th>\n",
       "      <th>attributed</th>\n",
       "      <th>device_model</th>\n",
       "      <th>ip_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170519</th>\n",
       "      <td>2019-04-18 03:43:09.185</td>\n",
       "      <td>1106971792117053344</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>5.186986602616849e+18</td>\n",
       "      <td>7209709704711395089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170521</th>\n",
       "      <td>2019-04-18 03:43:25.436</td>\n",
       "      <td>1106971792117053344</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>5.186986602616849e+18</td>\n",
       "      <td>7209709704711395089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170525</th>\n",
       "      <td>2019-04-18 03:43:21.320</td>\n",
       "      <td>1106971792117053344</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>5.186986602616849e+18</td>\n",
       "      <td>7209709704711395089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170529</th>\n",
       "      <td>2019-04-18 03:43:08.996</td>\n",
       "      <td>1106971792117053344</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>5.186986602616849e+18</td>\n",
       "      <td>7209709704711395089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171835</th>\n",
       "      <td>2019-04-19 17:01:38.181</td>\n",
       "      <td>1117811498061299916</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0574023248014715e+18</td>\n",
       "      <td>3382054713307838865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date             ref_hash application_id  \\\n",
       "170519 2019-04-18 03:43:09.185  1106971792117053344             65   \n",
       "170521 2019-04-18 03:43:25.436  1106971792117053344             65   \n",
       "170525 2019-04-18 03:43:21.320  1106971792117053344             65   \n",
       "170529 2019-04-18 03:43:08.996  1106971792117053344             65   \n",
       "171835 2019-04-19 17:01:38.181  1117811498061299916             65   \n",
       "\n",
       "        attributed            device_model           ip_address  \n",
       "170519       False   5.186986602616849e+18  7209709704711395089  \n",
       "170521       False   5.186986602616849e+18  7209709704711395089  \n",
       "170525       False   5.186986602616849e+18  7209709704711395089  \n",
       "170529       False   5.186986602616849e+18  7209709704711395089  \n",
       "171835       False  3.0574023248014715e+18  3382054713307838865  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_auctions(get_target_ids_chunk(1), all_days[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>ref_type_id</th>\n",
       "      <th>source_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289649</th>\n",
       "      <td>2019-04-18 19:58:47.826462</td>\n",
       "      <td>1114026657194419748</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317697</th>\n",
       "      <td>2019-04-18 23:34:28.216676</td>\n",
       "      <td>1102680423242413676</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317713</th>\n",
       "      <td>2019-04-18 23:34:36.035822</td>\n",
       "      <td>1102680423242413676</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317978</th>\n",
       "      <td>2019-04-18 23:42:35.347774</td>\n",
       "      <td>1102680423242413676</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318297</th>\n",
       "      <td>2019-04-18 23:44:54.822177</td>\n",
       "      <td>1102680423242413676</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date             ref_hash ref_type_id source_id\n",
       "289649 2019-04-18 19:58:47.826462  1114026657194419748           1         0\n",
       "317697 2019-04-18 23:34:28.216676  1102680423242413676           1         1\n",
       "317713 2019-04-18 23:34:36.035822  1102680423242413676           1         1\n",
       "317978 2019-04-18 23:42:35.347774  1102680423242413676           1         1\n",
       "318297 2019-04-18 23:44:54.822177  1102680423242413676           1         1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML: Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Approach 1: mean value per device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions = load_auctions()\n",
    "\n",
    "df_auctions2 = process_time_diffs(df_auctions)\n",
    "\n",
    "current_predictions = df_auctions2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()\n",
    "\n",
    "target = store_predictions(target_df=target, new_values=current_predictions, value_column_name='diff_in_sec', suffix='_st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_auctions\n",
    "del df_auctions2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs = load_installs()\n",
    "\n",
    "df_installs2 = process_time_diffs(df_installs)\n",
    "\n",
    "current_predictions = df_installs2[['ref_hash','diff_in_sec']].groupby('ref_hash', as_index=False).mean()\n",
    "\n",
    "target = store_predictions(target_df=target, new_values=current_predictions, value_column_name='diff_in_sec', suffix='_sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_installs\n",
    "del df_installs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(target, description=\"por cada grupo, avg. de los tiempos entre cada registro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Approach 1: mean value per device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Approach 2: mean value per device taking time from one common start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions = load_auctions(days=get_n_3_days(1))\n",
    "\n",
    "df_auctions2 = process_time_diffs_vs_min_day(df_auctions)\n",
    "\n",
    "current_predictions = df_auctions2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()\n",
    "\n",
    "target = store_predictions(target_df=target, new_values=current_predictions, value_column_name='diff_in_sec', suffix='_st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_auctions\n",
    "del df_auctions2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs = load_installs(days=get_n_3_days(1))\n",
    "\n",
    "df_installs2 = process_time_diffs_vs_min_day(df_installs)\n",
    "\n",
    "current_predictions = df_installs2[['ref_hash','diff_in_sec']].groupby('ref_hash', as_index=False).mean()\n",
    "\n",
    "target = store_predictions(target_df=target, new_values=current_predictions, value_column_name='diff_in_sec', suffix='_sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_installs\n",
    "del df_installs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(target, description=\"por cada grupo, avg. de los tiempos tomados a partir del primer dia de los elegidos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## End of Approach 2: mean value per device taking time from one common start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Approach 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define current users/days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_users = get_target_ids()\n",
    "current_days = get_n_3_days(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = load_clicks(current_users, current_days)\n",
    "df_installs = load_installs(current_users, current_days)\n",
    "df_events = load_events(current_users, current_days)\n",
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.727891\n",
      "2.071247\n",
      "6.177316\n",
      "25.952431\n"
     ]
    }
   ],
   "source": [
    "print(df_clicks.memory_usage(deep=True).sum()/1e6)\n",
    "print(df_installs.memory_usage(deep=True).sum()/1e6)\n",
    "print(df_events.memory_usage(deep=True).sum()/1e6)\n",
    "print(df_auctions.memory_usage(deep=True).sum()/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate time diffs per ref hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = process_time_diffs(df_clicks)\n",
    "df_installs = process_time_diffs(df_installs)\n",
    "df_events = process_time_diffs(df_events)\n",
    "df_auctions = process_time_diffs(df_auctions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append 'em!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_source_col(df_clicks, \"clicks\")\n",
    "set_source_col(df_installs, \"installs\")\n",
    "set_source_col(df_events, \"events\")\n",
    "set_source_col(df_auctions, \"auctions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = df_clicks.append(df_installs, sort=False).append(df_events, sort=False).append(df_auctions, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended.diff_in_sec = appended.diff_in_sec.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "976372"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = fill_all_nans(appended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = set_observed_column(appended, \"auctions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185944, 15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>date</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>source_csv</th>\n",
       "      <th>application_id</th>\n",
       "      <th>attributed</th>\n",
       "      <th>implicit</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>session_user_agent</th>\n",
       "      <th>device_language</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>diff_in_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 14:21:13.536</td>\n",
       "      <td>7425652559562776089</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10276</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 04:26:38.599</td>\n",
       "      <td>9001894065986101363</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10279</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-18 04:31:18.746</td>\n",
       "      <td>7906060474484893014</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10296</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 04:26:56.196</td>\n",
       "      <td>4164621178487252757</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10297</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 04:27:00.527</td>\n",
       "      <td>4164621178487252757</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_id                    date             ref_hash source_csv  \\\n",
       "1001          1 2019-04-18 14:21:13.536  7425652559562776089     clicks   \n",
       "10276         1 2019-04-18 04:26:38.599  9001894065986101363     clicks   \n",
       "10279         3 2019-04-18 04:31:18.746  7906060474484893014     clicks   \n",
       "10296         1 2019-04-18 04:26:56.196  4164621178487252757     clicks   \n",
       "10297         1 2019-04-18 04:27:00.527  4164621178487252757     clicks   \n",
       "\n",
       "      application_id attributed implicit device_brand device_model  \\\n",
       "1001             NaN        NaN      NaN          NaN          NaN   \n",
       "10276            NaN        NaN      NaN          NaN          NaN   \n",
       "10279            NaN        NaN      NaN          NaN          NaN   \n",
       "10296            NaN        NaN      NaN          NaN          NaN   \n",
       "10297            NaN        NaN      NaN          NaN          NaN   \n",
       "\n",
       "      session_user_agent device_language ip_address  diff_in_sec  \n",
       "1001                 NaN             NaN        NaN          NaN  \n",
       "10276                NaN             NaN        NaN          NaN  \n",
       "10279                NaN             NaN        NaN          NaN  \n",
       "10296                NaN             NaN        NaN          NaN  \n",
       "10297                NaN             NaN        NaN          NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = appended.drop(['diff_in_sec','observed','date'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct y_train array of tuples as needed.\n",
    "# To understand this, see: https://scikit-survival.readthedocs.io/en/latest/generated/sksurv.util.Surv.html#sksurv.util.Surv.from_dataframe\n",
    "from sksurv.util import Surv\n",
    "\n",
    "helper = Surv()\n",
    "\n",
    "y_train = helper.from_dataframe('observed','diff_in_sec', appended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.preprocessing import OneHotEncoder\n",
    "\n",
    "X_train_numeric = OneHotEncoder().fit_transform(X_train)\n",
    "X_train_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "\n",
    "estimator = CoxPHSurvivalAnalysis(alpha=0.001)\n",
    "estimator.fit(X_train_numeric, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(estimator.coef_, index=X_train_numeric.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "El approach con `scikit-survival` fue abandonado debido a las incesantes complicaciones debidas a la pobre implementacion de la libreria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## End of Approach 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Approach 4: Appendear todos los csvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define current users/days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_users = get_target_ids()\n",
    "current_days = get_n_3_days(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = load_clicks(current_users, current_days)\n",
    "df_installs = load_installs(current_users, current_days)\n",
    "df_events = load_events(current_users, current_days)\n",
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.728784\n",
      "2.077395\n",
      "7.337713\n",
      "17.569194\n"
     ]
    }
   ],
   "source": [
    "print(df_clicks.memory_usage(deep=True).sum()/1e6)\n",
    "print(df_installs.memory_usage(deep=True).sum()/1e6)\n",
    "print(df_events.memory_usage(deep=True).sum()/1e6)\n",
    "print(df_auctions.memory_usage(deep=True).sum()/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate time diffs per ref hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_auctions = process_time_diffs(df_auctions)\n",
    "\n",
    "# df_auctions.drop('diff_in_sec',axis='columns',inplace=True)\n",
    "\n",
    "# df_auctions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append 'em!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_source_col(df_clicks, \"clicks\")\n",
    "set_source_col(df_installs, \"installs\")\n",
    "set_source_col(df_events, \"events\")\n",
    "set_source_col(df_auctions, \"auctions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = df_clicks.append(df_installs, sort=False).append(df_events, sort=False).append(df_auctions, sort=False)\n",
    "\n",
    "# appended.diff_in_sec = appended.diff_in_sec.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>date</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>source_csv</th>\n",
       "      <th>application_id</th>\n",
       "      <th>attributed</th>\n",
       "      <th>implicit</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>session_user_agent</th>\n",
       "      <th>device_language</th>\n",
       "      <th>ip_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-23 06:25:11.338</td>\n",
       "      <td>3212714779716119835</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-23 05:00:41.900</td>\n",
       "      <td>5208157685279319362</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-22 14:37:40.671</td>\n",
       "      <td>625748796078289051</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>6</td>\n",
       "      <td>2019-04-22 16:29:00.513</td>\n",
       "      <td>571264229455029355</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-22 16:22:59.784</td>\n",
       "      <td>2154661459299925256</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     source_id                    date             ref_hash source_csv  \\\n",
       "136          0 2019-04-23 06:25:11.338  3212714779716119835     clicks   \n",
       "393          1 2019-04-23 05:00:41.900  5208157685279319362     clicks   \n",
       "1189         3 2019-04-22 14:37:40.671   625748796078289051     clicks   \n",
       "1363         6 2019-04-22 16:29:00.513   571264229455029355     clicks   \n",
       "1373         1 2019-04-22 16:22:59.784  2154661459299925256     clicks   \n",
       "\n",
       "     application_id attributed implicit device_brand device_model  \\\n",
       "136             NaN        NaN      NaN          NaN          NaN   \n",
       "393             NaN        NaN      NaN          NaN          NaN   \n",
       "1189            NaN        NaN      NaN          NaN          NaN   \n",
       "1363            NaN        NaN      NaN          NaN          NaN   \n",
       "1373            NaN        NaN      NaN          NaN          NaN   \n",
       "\n",
       "     session_user_agent device_language ip_address  \n",
       "136                 NaN             NaN        NaN  \n",
       "393                 NaN             NaN        NaN  \n",
       "1189                NaN             NaN        NaN  \n",
       "1363                NaN             NaN        NaN  \n",
       "1373                NaN             NaN        NaN  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = get_time_to_event_of_interest(appended, \"auctions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = appended.loc[appended['source_csv'] != \"auctions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdf2 = pd.get_dummies(data=asdf.drop(['date','diff_in_sec','ref_hash'], axis='columns'), dummy_na=True)\n",
    "# asdf2[['date','diff_in_sec','ref_hash']] = asdf[['date','diff_in_sec','ref_hash']]\n",
    "\n",
    "# asdf2.attributed.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>date</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>source_csv</th>\n",
       "      <th>application_id</th>\n",
       "      <th>attributed</th>\n",
       "      <th>implicit</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>session_user_agent</th>\n",
       "      <th>device_language</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>diff_in_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6308583</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-21 00:00:34.215</td>\n",
       "      <td>1000169251625791246</td>\n",
       "      <td>events</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8054562877343293e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1675257172863076743</td>\n",
       "      <td>259200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078575</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-21 00:02:49.777</td>\n",
       "      <td>1000169251625791246</td>\n",
       "      <td>events</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8054562877343293e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1675257172863076743</td>\n",
       "      <td>259200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304584</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-21 00:07:01.266</td>\n",
       "      <td>1000169251625791246</td>\n",
       "      <td>events</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8054562877343293e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1675257172863076743</td>\n",
       "      <td>259200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-21 00:10:17.997</td>\n",
       "      <td>1000169251625791246</td>\n",
       "      <td>events</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8054562877343293e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1675257172863076743</td>\n",
       "      <td>259200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304406</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-21 00:12:16.505</td>\n",
       "      <td>1000169251625791246</td>\n",
       "      <td>events</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8054562877343293e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1675257172863076743</td>\n",
       "      <td>259200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_id                    date             ref_hash source_csv  \\\n",
       "6308583       NaN 2019-04-21 00:00:34.215  1000169251625791246     events   \n",
       "3078575       NaN 2019-04-21 00:02:49.777  1000169251625791246     events   \n",
       "6304584       NaN 2019-04-21 00:07:01.266  1000169251625791246     events   \n",
       "6304457       NaN 2019-04-21 00:10:17.997  1000169251625791246     events   \n",
       "6304406       NaN 2019-04-21 00:12:16.505  1000169251625791246     events   \n",
       "\n",
       "        application_id attributed implicit device_brand  \\\n",
       "6308583             21      False      NaN          NaN   \n",
       "3078575             21      False      NaN          NaN   \n",
       "6304584             21      False      NaN          NaN   \n",
       "6304457             21      False      NaN          NaN   \n",
       "6304406             21      False      NaN          NaN   \n",
       "\n",
       "                   device_model session_user_agent device_language  \\\n",
       "6308583  1.8054562877343293e+18                NaN             NaN   \n",
       "3078575  1.8054562877343293e+18                NaN             NaN   \n",
       "6304584  1.8054562877343293e+18                NaN             NaN   \n",
       "6304457  1.8054562877343293e+18                NaN             NaN   \n",
       "6304406  1.8054562877343293e+18                NaN             NaN   \n",
       "\n",
       "                  ip_address  diff_in_sec  \n",
       "6308583  1675257172863076743     259200.0  \n",
       "3078575  1675257172863076743     259200.0  \n",
       "6304584  1675257172863076743     259200.0  \n",
       "6304457  1675257172863076743     259200.0  \n",
       "6304406  1675257172863076743     259200.0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = appended.drop('diff_in_sec', axis='columns')\n",
    "\n",
    "X_train = col_to_bool(X_train,['attributed','implicit'])\n",
    "\n",
    "y_train = appended['diff_in_sec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = appended.drop('diff_in_sec', axis='columns')\n",
    "\n",
    "X_test = col_to_bool(X_test,['attributed','implicit'])\n",
    "\n",
    "y_test = appended['diff_in_sec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "http-kit/2.0                                                                                                                                                           1142\n",
       "adjust.com                                                                                                                                                              314\n",
       "HasOffers Mobile AppTracking v1.0                                                                                                                                        58\n",
       "Apsalar-Postback                                                                                                                                                         50\n",
       "Mozilla/5.0 (iPhone; CPU iPhone OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148                                                            10\n",
       "Dalvik/2.1.0 (Linux; U; Android 8.1.0; JKM-LX3 Build/HUAWEIJKM-LX3)                                                                                                       3\n",
       "Branch Metrics API                                                                                                                                                        3\n",
       "Mozilla/5.0 (iPhone; CPU iPhone OS 12_1_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/16D57                                                            2\n",
       "Mozilla/5.0 (Linux; Android 8.1.0; SM-J610G Build/M1AJQ) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.133 Mobile Safari/535.19                                 2\n",
       "Dalvik/2.1.0 (Linux; U; Android 8.0.0; Moto Z2 Play Build/OPSS27.76-12-25-15)                                                                                             2\n",
       "Dalvik/2.1.0 (Linux; U; Android 8.1.0; Moto G (5) Build/OPPS28.85-13-6)                                                                                                   2\n",
       "Dalvik/2.1.0 (Linux; U; Android 6.0.1; SM-G532M Build/MMB29T)                                                                                                             2\n",
       "Dalvik/2.1.0 (Linux; U; Android 5.1.1; SM-G531H Build/LMY48B)                                                                                                             2\n",
       "Mozilla/5.0 (Linux; Android 5.1.1; SM-J200G Build/LMY47X; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/43.0.2357.121 Mobile Safari/537.36                2\n",
       "Dalvik/2.1.0 (Linux; U; Android 8.0.0; SM-J810M Build/R16NW)                                                                                                              2\n",
       "Dalvik/2.1.0 (Linux; U; Android 6.0.1; SM-J700M Build/MMB29K)                                                                                                             2\n",
       "Dalvik/2.1.0 (Linux; U; Android 8.0.0; PRA-LX3 Build/HUAWEIPRA-LX3)                                                                                                       2\n",
       "Mozilla/5.0 (Linux; Android 8.0.0; FLA-LX3 Build/HUAWEIFLA-LX3; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/67.0.3396.87 Mobile Safari/537.36           2\n",
       "Dalvik/2.1.0 (Linux; U; Android 7.1.1; Moto E (4) Build/NMA26.42-157)                                                                                                     2\n",
       "Mozilla/5.0 (Linux; Android 8.1.0; Moto G (5) Build/OPPS28.85-13-2; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/71.0.3578.99 Mobile Safari/537.36       2\n",
       "Name: session_user_agent, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.session_user_agent.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn API Reference:\n",
    "#         https://scikit-learn.org/stable/modules/classes.html\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "transformers = []\n",
    "# transformers.append((\"one_hot_source_id\",\n",
    "#                      OneHotEncoder(handle_unknown='ignore'),\n",
    "#                      ['source_id']))\n",
    "# transformers.append((\"one_hot_source_csv\",\n",
    "#                      OneHotEncoder(handle_unknown='ignore'),\n",
    "#                      ['source_csv']))\n",
    "# transformers.append((\"one_hot_device_brand\",\n",
    "#                      OneHotEncoder(handle_unknown='ignore'),\n",
    "#                      ['device_brand']))\n",
    "# transformers.append((\"one_hot_device_language\",\n",
    "#                      OneHotEncoder(handle_unknown='ignore'),\n",
    "#                      ['device_language']))\n",
    "# transformers.append((\"one_hot_ref_hash\",\n",
    "#                      OneHotEncoder(handle_unknown='ignore'),\n",
    "#                      ['ref_hash']))\n",
    "# transformers.append((\"one_hot_application_id\",\n",
    "#                      OneHotEncoder(handle_unknown='ignore'),\n",
    "#                      ['application_id']))\n",
    "\n",
    "# TODO agregar Feature hasher: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html#sklearn.feature_extraction.FeatureHasher\n",
    "transformers.append((\"text_session_user_agent\",\n",
    "                     HashingVectorizer(decode_error='ignore', strip_accents='unicode', lowercase=True, ngram_range=(1,3), norm='l1',alternate_sign=True),\n",
    "                     ['session_user_agent']))\n",
    "\n",
    "my_col_transformer = ColumnTransformer(transformers, remainder='drop', sparse_threshold=0.3, n_jobs=-1, transformer_weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "steps = []\n",
    "steps.append((\"imputer\", SimpleImputer(strategy='most_frequent')))\n",
    "\n",
    "steps.append((\"col_trans\",my_col_transformer))\n",
    "\n",
    "steps.append((\"svc\", LinearSVC()))\n",
    "\n",
    "my_pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "categorical_features = ['source_id','source_csv','device_brand','device_language','ref_hash','application_id']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "#     ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                  ('classifier', BaggingRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('cat', Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImputer(copy=True, fill_value='missing', missing_values=nan,\n",
       "       strategy='constant'...imators=10, n_jobs=None, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26629"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26629"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions_prediction = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions_prediction = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions_prediction['ref_hash'] = X_test.reset_index()['ref_hash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2026"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auctions_prediction.ref_hash.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## End of Approach 4: Appendear todos los csvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Approach 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_preds = pd.read_csv(\"../predictions/2019.06.21 - 14:32:47 by mati.csv\")\n",
    "\n",
    "prev_conversion_prediction = prev_preds.loc[prev_preds['ref_hash'].apply(lambda x: x[-3:]) == \"_sc\"].rename(columns={'obj':'prev_conversion_prediction'})\n",
    "prev_auction_prediction = prev_preds.loc[prev_preds['ref_hash'].apply(lambda x: x[-3:]) == \"_st\"].rename(columns={'obj':'prev_auction_prediction'})\n",
    "\n",
    "prev_conversion_prediction['ref_hash'] = prev_conversion_prediction['ref_hash'].apply(lambda x: x[:-3])\n",
    "prev_auction_prediction['ref_hash'] = prev_auction_prediction['ref_hash'].apply(lambda x: x[:-3])\n",
    "\n",
    "del prev_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_users = get_target_ids()\n",
    "current_days = get_n_3_days(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = load_clicks(current_users, current_days)\n",
    "\n",
    "df_installs = load_installs(current_users, current_days)\n",
    "\n",
    "df_events = load_events(current_users, current_days)\n",
    "\n",
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predigamos auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_installs\n",
    "\n",
    "y_train = df_installs.merge(prev_auction_prediction, how='left')['prev_auction_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_installs\n",
    "\n",
    "y_test = df_installs.merge(prev_auction_prediction, how='left')['prev_auction_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "categorical_features = ['application_id','ref_hash','device_brand','device_model','device_language']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# text_features = ['session_user_agent']\n",
    "# text_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "#     ('vectorizer', HashingVectorizer(decode_error='ignore', strip_accents='unicode', lowercase=True, ngram_range=(1,3), norm='l1',alternate_sign=True))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "#         ('tex', text_transformer, text_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', ExtraTreesRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rozanecm/Documents/Univerza/UBA/7506 Organizacion de Datos/1c2019/tp2/venv/lib/python3.5/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('cat', Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImputer(copy=True, fill_value='missing', missing_values=nan,\n",
       "       strategy='constant'...mators=10, n_jobs=None,\n",
       "          oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct_pred_by_install = pd.DataFrame(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Approach 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_users = get_target_ids()\n",
    "current_days = get_n_3_days(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "SimpleImputer(strategy='constant', fill_value='missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions2 = process_time_diffs(df_auctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_predictions = df_auctions2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = load_clicks(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs = load_installs(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = load_events(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>application_id</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>attributed</th>\n",
       "      <th>implicit</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>session_user_agent</th>\n",
       "      <th>device_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2019-04-19 04:59:59.551</td>\n",
       "      <td>4</td>\n",
       "      <td>6039594975543824058</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.794880020077885e+18</td>\n",
       "      <td>http-kit/2.0</td>\n",
       "      <td>8.441417429938962e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>2019-04-18 03:30:57.862</td>\n",
       "      <td>4</td>\n",
       "      <td>3015728650082320700</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.794880020077885e+18</td>\n",
       "      <td>http-kit/2.0</td>\n",
       "      <td>8.441417429938962e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>2019-04-20 04:45:18.565</td>\n",
       "      <td>4</td>\n",
       "      <td>7202307703553170861</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.794880020077885e+18</td>\n",
       "      <td>http-kit/2.0</td>\n",
       "      <td>8.441417429938962e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>2019-04-20 19:09:02.692</td>\n",
       "      <td>4</td>\n",
       "      <td>2859383778838750439</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.794880020077885e+18</td>\n",
       "      <td>http-kit/2.0</td>\n",
       "      <td>8.441417429938962e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>2019-04-19 04:28:23.058</td>\n",
       "      <td>14</td>\n",
       "      <td>9041396510174802610</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.208834667126999e+18</td>\n",
       "      <td>6.763740053215609e+18</td>\n",
       "      <td>Mozilla/5.0 (Linux; Android 7.0; Moto G (5) Bu...</td>\n",
       "      <td>3.3013777759776993e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date application_id             ref_hash  attributed  \\\n",
       "418  2019-04-19 04:59:59.551              4  6039594975543824058       False   \n",
       "946  2019-04-18 03:30:57.862              4  3015728650082320700       False   \n",
       "1088 2019-04-20 04:45:18.565              4  7202307703553170861       False   \n",
       "1188 2019-04-20 19:09:02.692              4  2859383778838750439       False   \n",
       "2088 2019-04-19 04:28:23.058             14  9041396510174802610       False   \n",
       "\n",
       "      implicit           device_brand           device_model  \\\n",
       "418      False                    NaN  6.794880020077885e+18   \n",
       "946      False                    NaN  6.794880020077885e+18   \n",
       "1088     False                    NaN  6.794880020077885e+18   \n",
       "1188     False                    NaN  6.794880020077885e+18   \n",
       "2088     False  2.208834667126999e+18  6.763740053215609e+18   \n",
       "\n",
       "                                     session_user_agent  \\\n",
       "418                                        http-kit/2.0   \n",
       "946                                        http-kit/2.0   \n",
       "1088                                       http-kit/2.0   \n",
       "1188                                       http-kit/2.0   \n",
       "2088  Mozilla/5.0 (Linux; Android 7.0; Moto G (5) Bu...   \n",
       "\n",
       "             device_language  \n",
       "418    8.441417429938962e+18  \n",
       "946    8.441417429938962e+18  \n",
       "1088   8.441417429938962e+18  \n",
       "1188   8.441417429938962e+18  \n",
       "2088  3.3013777759776993e+18  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = store_predictions(target_df=target, new_values=current_predictions, value_column_name='diff_in_sec', suffix='_st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_auctions\n",
    "del df_auctions2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_installs = load_installs()\n",
    "\n",
    "# df_installs2 = process_time_diffs(df_installs)\n",
    "\n",
    "# current_predictions = df_installs2[['ref_hash','diff_in_sec']].groupby('ref_hash', as_index=False).mean()\n",
    "\n",
    "# target = store_predictions(target_df=target, new_values=current_predictions, value_column_name='diff_in_sec', suffix='_sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_installs\n",
    "del df_installs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_submission(target, description=\"por cada grupo, avg. de los tiempos entre cada registro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Approach 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_window_1 = pd.read_csv('df_auctions_window_1.csv', dtype={'ref_hash':'category'})\n",
    "auction_window_2 = pd.read_csv('df_auctions_window_2.csv', dtype={'ref_hash':'category'})\n",
    "auction_window_3 = pd.read_csv('df_auctions_window_3.csv', dtype={'ref_hash':'category'})\n",
    "auction_window_4 = pd.read_csv('df_auctions_window_4.csv', dtype={'ref_hash':'category'})\n",
    "auction_window_5 = pd.read_csv('df_auctions_window_5.csv', dtype={'ref_hash':'category'})\n",
    "auction_window_6 = pd.read_csv('df_auctions_window_6.csv', dtype={'ref_hash':'category'})\n",
    "\n",
    "installs_window_1 = pd.read_csv('df_installs_window_1.csv', dtype={'ref_hash':'category'})\n",
    "installs_window_2 = pd.read_csv('df_installs_window_2.csv', dtype={'ref_hash':'category'})\n",
    "installs_window_3 = pd.read_csv('df_installs_window_3.csv', dtype={'ref_hash':'category'})\n",
    "installs_window_4 = pd.read_csv('df_installs_window_4.csv', dtype={'ref_hash':'category'})\n",
    "installs_window_5 = pd.read_csv('df_installs_window_5.csv', dtype={'ref_hash':'category'})\n",
    "installs_window_6 = pd.read_csv('df_installs_window_6.csv', dtype={'ref_hash':'category'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn API Reference:\n",
    "#         https://scikit-learn.org/stable/modules/classes.html\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "transformers = []\n",
    "\n",
    "transformers.append((\"cat\",\n",
    "                     Pipeline(steps=[\n",
    "                         (\"category_imputer\", SimpleImputer(fill_value=\"\")),\n",
    "                         (\"one_hot\", OneHotEncoder(handle_unknown='ignore')),\n",
    "                     ]),\n",
    "                     ['source_id','brand']))\n",
    "\n",
    "transformers.append((\"num\",\n",
    "                     Pipeline(steps=[\n",
    "                         (\"num_imputer\", SimpleImputer()),\n",
    "                         (\"num_transformer\", StandardScaler())\n",
    "                     ]),\n",
    "                   ['latitude','longitude','timeToClick','touchX','touchY']))\n",
    "\n",
    "transformers.append((\"bool\",\n",
    "                    Pipeline(steps=[\n",
    "                        (\"bool_imputer\", SimpleImputer(strategy='most_frequent')),\n",
    "                    ]),\n",
    "                     ['wifi_connection']))\n",
    "\n",
    "# TODO agregar Feature hasher: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html#sklearn.feature_extraction.FeatureHasher\n",
    "# transformers.append((\"text_session_user_agent\",\n",
    "#                      HashingVectorizer(decode_error='ignore', strip_accents='unicode', lowercase=True, ngram_range=(1,3), norm='l1',alternate_sign=True),\n",
    "#                      ['session_user_agent']))\n",
    "\n",
    "my_col_transformer = ColumnTransformer(transformers, remainder='passthrough', sparse_threshold=0.3, n_jobs=-1, transformer_weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', my_col_transformer),\n",
    "                      ('regressor', ExtraTreesRegressor(n_estimators=100)),\n",
    "#                       ('nn', MLPRegressor()),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_users = get_target_ids()\n",
    "current_days = get_n_3_days(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = load_clicks(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = df_clicks.merge(auction_window_1, on='ref_hash', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks['wifi_connection'] = df_clicks['wifi_connection'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=-1, remainder='passthrough', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('cat', Pipeline(memory=None,\n",
       "     steps=[('category_imputer', SimpleImputer(copy=True, fill_value='', missing_values=nan, strategy='mean',\n",
       "  ...ators=100, n_jobs=None,\n",
       "          oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(df_clicks[['source_id','latitude','longitude','brand','timeToClick','touchX','touchY','wifi_connection']], df_clicks['diff_in_sec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs = load_installs(current_users, current_days)\n",
    "\n",
    "df_events = load_events(current_users, current_days)\n",
    "\n",
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
