{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will allow you to see all column names & rows when you are doing .head(). None of the column name will be truncated.\n",
    "# source: https://stackoverflow.com/questions/49188960/how-to-show-all-of-columns-name-on-pandas-dataframe\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auctions.csv\t\t\t\t\t\t2412.11824\n",
      ".ipynb_checkpoints\t\t\t\t\t\t0.004096\n",
      "target_competencia_ids.csv\t\t\t\t\t\t0.200915\n",
      "installs.csv\t\t\t\t\t\t123.502317\n",
      "desc.json\t\t\t\t\t\t0.009146\n",
      "Recomendaciones y aclaraciones.docx\t\t\t\t\t\t0.006909\n",
      "clicks.csv\t\t\t\t\t\t16.147446\n",
      "events.csv\t\t\t\t\t\t2252.988966\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('../data/'):\n",
    "    print(file + '\\t\\t\\t\\t\\t\\t' + str(os.stat(\"../data/\" + file).st_size/1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "# days to consider\n",
    "all_days = [18,19,20,21,22,23,24,25,26]\n",
    "\n",
    "secs_in_3_days = 3*24*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_3_days(n):\n",
    "    \"\"\"\n",
    "    get nth block of 3 consecutive days\n",
    "    n can go from 1 to 7.\n",
    "    If n == 8, then last two days are given.\n",
    "    If n == 9, then last day is given.\n",
    "    \"\"\"\n",
    "    n -= 1\n",
    "    return all_days[n:n+3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "# load target\n",
    "def load_target():\n",
    "    target = pd.read_csv('../data/target_competencia_ids.csv')\n",
    "\n",
    "    # to avoid misunderstandings with data when predicting, and avoid accidentally predicting value zero\n",
    "#     target.obj = np.nan\n",
    "    \n",
    "    return target\n",
    "\n",
    "# para que quede cargado desde el principio\n",
    "target = load_target()\n",
    "\n",
    "# target ids related\n",
    "def get_target_ids():\n",
    "    \"\"\" get all target ids \"\"\"\n",
    "    return target['ref_hash'].apply(lambda x: x[:-3]).unique()\n",
    "\n",
    "def get_target_ids_chunk(chunk_num):\n",
    "    \"\"\" chunk num can go from 1 to 41 \"\"\"\n",
    "    chunk_size = 100\n",
    "    start = (chunk_num - 1) * chunk_size\n",
    "    stop = chunk_size * chunk_num\n",
    "    return get_target_ids()[start:stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "# para guardar predicciones\n",
    "import time\n",
    "def _get_filename(my_name, timestamp):\n",
    "    return \"../predictions/\" + timestamp + \" by \" + my_name + \".csv\"\n",
    "\n",
    "def _save_description(authors_name, timestamp, submission_description):\n",
    "    f = open(\"../predictions/\" + authors_name + \".txt\",\"a\")\n",
    "    f.write(timestamp + \": \" + submission_description + '\\n')\n",
    "    f.close()\n",
    "\n",
    "def save_submission(submission_df, authors_name=\"mati\", description = \"no description\"):\n",
    "    timestamp = time.strftime(\"%Y.%m.%d - %H:%M:%S\")\n",
    "    submission_df.to_csv(_get_filename(authors_name, timestamp), index=False)\n",
    "    _save_description(authors_name, timestamp, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_predictions(target_df, new_values, value_column_name, suffix):\n",
    "    \"\"\"\n",
    "    adds predictions from value_column_name from new_values df\n",
    "    to target_df merging by ref_hash and the given suffix \n",
    "    suffix: \"_st\" for auction prediction\n",
    "            \"_sc\" for conversion prediction\n",
    "    \"\"\"\n",
    "    new_values['ref_hash'] = new_values['ref_hash'] + suffix\n",
    "    \n",
    "    target_df = target_df.merge(new_values[['ref_hash',value_column_name]], how='left', on='ref_hash')\n",
    "    \n",
    "    target_df.fillna(0, inplace=True)\n",
    "    \n",
    "#     assign values to 'obj' column and remove the column added on merge.\n",
    "#     after sum, fillna is needed because there are values which are left as NaNs.\n",
    "    target_df['obj'] = target_df['obj'] + target_df[value_column_name]\n",
    "    \n",
    "    target_df.drop([value_column_name], axis='columns', inplace=True)\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "# play a sound\n",
    "import os\n",
    "def ring(duration = 1, freq = 1500):\n",
    "    \"\"\" play tone of duration in seconds and freq in Hz. \"\"\"\n",
    "    os.system('play --no-show-progress --null --channels 1 synth %s sine %f' % (duration, freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_source_col(df, source):\n",
    "    \"\"\"\n",
    "    for a given dataframe, create a column indicating\n",
    "    from which csv file it originated\n",
    "    \"\"\"\n",
    "    df['source_csv'] = source\n",
    "\n",
    "    \n",
    "def process_time_diffs(df):\n",
    "    \"\"\"\n",
    "    create column indicating difference between two\n",
    "    consecutive registers for each device id\n",
    "    \"\"\"\n",
    "    asdf = df\n",
    "    \n",
    "    asdf = asdf.sort_values(['date'])\n",
    "    \n",
    "    asdf['diff'] = asdf.groupby(['ref_hash'])['date'].diff()\n",
    "\n",
    "    asdf['diff'].fillna(value=asdf['date']-asdf['date'].dt.floor('d'), inplace=True)\n",
    "\n",
    "    asdf['diff_in_sec'] = asdf['diff'].dt.total_seconds()\n",
    "\n",
    "    asdf.drop('diff', axis='columns', inplace=True)\n",
    "    \n",
    "    return asdf\n",
    "\n",
    "\n",
    "def process_time_diffs_vs_min_day(df):\n",
    "    \"\"\"\n",
    "    create column indicating difference between\n",
    "    time in registers and min day in df\n",
    "    \"\"\"\n",
    "    asdf = df\n",
    "\n",
    "    min_timestamp = asdf['date'].min().floor('d')\n",
    "\n",
    "    asdf['diff'] = asdf['date'] - min_timestamp\n",
    "\n",
    "    asdf['diff_in_sec'] = asdf['diff'].dt.total_seconds()\n",
    "\n",
    "    asdf.drop('diff', axis='columns', inplace=True)\n",
    "    \n",
    "    return asdf\n",
    "\n",
    "def is_source_that_defines_death(data, source_that_defines_death):\n",
    "    return data == source_that_defines_death\n",
    "\n",
    "def set_observed_column(df, csv_source_that_defines_death):\n",
    "    \"\"\"\n",
    "    create column indicating if death has been observed or not.\n",
    "    \"\"\"\n",
    "    asdf = df\n",
    "    \n",
    "    asdf['observed'] = asdf.source_csv.apply(lambda x: is_source_that_defines_death(x,csv_source_that_defines_death))\n",
    "    \n",
    "    return asdf\n",
    "\n",
    "\n",
    "def fill_with_mode(x):\n",
    "    \"\"\"\n",
    "    If there is any value present in group, fill nans with the mode of the group. \n",
    "    If there are all nans, leave them all as nans.\n",
    "    \"\"\"\n",
    "    if x.isnull().all():\n",
    "        return np.nan\n",
    "    else:\n",
    "        mode = x.mode()[0]\n",
    "        return x.fillna(mode)\n",
    "\n",
    "    \n",
    "def fill_nans(df):\n",
    "    \"\"\" Fill nan spaces with the mode of the group by ref_hash. \"\"\"\n",
    "    nans_filled = df\n",
    "    nans_filled = nans_filled.sort_values(by=['ref_hash','date'])\n",
    "\n",
    "    asdf = nans_filled.groupby('ref_hash', as_index=False, sort=False).transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "    asdf['ref_hash'] = nans_filled['ref_hash']\n",
    "    \n",
    "    return asdf\n",
    "\n",
    "#     nans_filled = df.groupby('ref_hash', as_index=False, sort=False).transform(lambda x: x.ffill().bfill())\n",
    "    \n",
    "#     for col in nans_filled.columns:\n",
    "#         print(\"filling column \" + col)\n",
    "# #         col_mode = nans_filled[col].mode()[0]\n",
    "#         nans_filled[col].fillna(col_mode, inplace=True)\n",
    "    \n",
    "#     nans_filled['ref_hash'] = df['ref_hash']\n",
    "#     return nans_filled\n",
    "\n",
    "# def fill_all_nans_but_diff_in_sec(df):\n",
    "#     nans_filled = fill_all_nans(df.drop(['diff_in_sec'],axis='columns'))\n",
    "#     nans_filled['diff_in_sec'] = df['diff_in_sec']\n",
    "#     return nans_filled\n",
    "\n",
    "# def object_to_categorical(df):\n",
    "#     \"\"\"\n",
    "#     Transform all 'object' dtypes to 'category'.\n",
    "#     The following answers helped address the issue:\n",
    "#         - https://stackoverflow.com/a/46762926\n",
    "#         - https://stackoverflow.com/a/39092877\n",
    "#     \"\"\"\n",
    "#     asdf = df\n",
    "    \n",
    "#     for col in asdf.columns:\n",
    "#         if asdf[col].dtype.kind == 'O':\n",
    "#             print(col)\n",
    "#             asdf[col] = asdf[col].astype('category')\n",
    "        \n",
    "#     return asdf\n",
    "\n",
    "def col_to_bool(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype('bool')\n",
    "    return df\n",
    "\n",
    "def get_time_to_event_of_interest(df, source_of_interest):\n",
    "    asdf = df\n",
    "    \n",
    "    asdf = asdf.sort_values(['ref_hash','date'])\n",
    "\n",
    "    asdf['timestamp_of_next_occurrence'] = asdf['date']\n",
    "    asdf.loc[asdf['source_csv'] != source_of_interest, 'timestamp_of_next_occurrence'] = np.nan\n",
    "\n",
    "    # asdf = nans_filled.groupby('ref_hash', as_index=False, sort=False).transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "    asdf['timestamp_of_next_occurrence'] = asdf['timestamp_of_next_occurrence'].bfill().ffill()\n",
    "\n",
    "    asdf['diff_in_sec'] = asdf['date']-asdf['timestamp_of_next_occurrence']\n",
    "    \n",
    "    asdf['diff_in_sec'] = asdf['diff_in_sec'].dt.total_seconds()\n",
    "\n",
    "    asdf['diff_in_sec'] = asdf['diff_in_sec'].apply(lambda x: x if x <= secs_in_3_days else secs_in_3_days)\n",
    "    asdf['diff_in_sec'] = asdf['diff_in_sec'].apply(lambda x: x if x > 0 else secs_in_3_days)\n",
    "    \n",
    "    asdf = asdf.drop('timestamp_of_next_occurrence', axis='columns')\n",
    "    \n",
    "    return asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dfs loading functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de appendear los 4 dfs y rellenar los nans con la moda por cada grupo, se ha observado, con una muestra de device ids (ref_hashes), la siguiente proporcion de nans:\n",
    "\n",
    "> source_id has 0.0% of nans.<br>\n",
    "date has 0.0% of nans.<br>\n",
    "latitude has 68.65% of nans.<br>\n",
    "longitude has 68.65% of nans.<br>\n",
    "wifi_connection has 68.65% of nans.<br>\n",
    "carrier_id has 68.65% of nans.<br>\n",
    "os_minor has 68.65% of nans.<br>\n",
    "os_major has 68.65% of nans.<br>\n",
    "specs_brand has 68.65% of nans.<br>\n",
    "timeToClick has 68.65% of nans.<br>\n",
    "touchX has 68.65% of nans.<br>\n",
    "touchY has 68.65% of nans.<br>\n",
    "ref_type has 68.65% of nans.<br>\n",
    "diff_in_sec has 0.0% of nans.<br>\n",
    "source_csv has 0.0% of nans.<br>\n",
    "application_id has 0.0% of nans.<br>\n",
    "attributed has 0.0% of nans.<br>\n",
    "implicit has 0.0% of nans.<br>\n",
    "device_brand has 34.18% of nans.<br>\n",
    "device_model has 2.14% of nans.<br>\n",
    "session_user_agent has 0.13% of nans.<br>\n",
    "device_language has 3.31% of nans.<br>\n",
    "ip_address has 16.25% of nans.<br>\n",
    "ref_type_id has 0.0% of nans.<br>\n",
    "ref_hash has 0.0% of nans.<br>\n",
    "\n",
    "Se decide no trabajar con las columnas que tengan mas de 50% de nans.\n",
    "\n",
    "Codigo ejecutado:\n",
    "```python\n",
    "for col in nans_filled.columns:\n",
    "    total_rows = nans_filled.shape[0]\n",
    "    print(str(col) + \" has \" + str(100*nans_filled[col].isna().sum()/total_rows) + \"% of nans.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "clicks_cols = ['source_id','created','ref_hash',]\n",
    "\n",
    "clicks_dtypes = {\n",
    "#     'advertiser_id':'category',\n",
    "#                  'action_id':'category',\n",
    "                 'source_id':'category',\n",
    "#                  'country_code':'category',\n",
    "#                  'latitude':'float64',\n",
    "#                  'longitude':'float64',\n",
    "#                  'wifi_connection':'bool',\n",
    "#                  'carrier_id':'category',\n",
    "#                  'trans_id':'category',\n",
    "#                  'os_minor':'category',\n",
    "#                  'agent_device':'category',\n",
    "#                  'os_major':'category',\n",
    "#                  'specs_brand':'category',\n",
    "#                  'brand':'category',\n",
    "#                  'timeToClick':'float64',\n",
    "#                  'touchX':'object',\n",
    "#                  'touchY':'object',\n",
    "#                  'ref_type':'category',\n",
    "                 'ref_hash':'category'}\n",
    "\n",
    "def load_clicks(users=get_target_ids(), days=all_days):\n",
    "    \"\"\"\n",
    "    load clicks csv, only users and days specified in users and days lists.\n",
    "    If lists left empty, consider whole set of users and days respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_clicks = pd.read_csv('../data/clicks.csv', engine='c', dtype=clicks_dtypes, parse_dates=['created'], usecols=clicks_cols)\n",
    "    \n",
    "    def load_condition(chunk):\n",
    "        return chunk['ref_hash'].isin(users) & chunk['created'].dt.day.isin(days)\n",
    "    \n",
    "    df = df_clicks.loc[load_condition(df_clicks)].copy()\n",
    "    \n",
    "    df.rename(columns={'created':'date'}, inplace=True)\n",
    "    \n",
    "    df['date'] = df['date'].dt.tz_localize(None)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "installs_cols = ['created','application_id','ref_hash','attributed','implicit','device_brand','device_model','session_user_agent','device_language']\n",
    "\n",
    "installs_dtypes = {\"application_id\":          \"category\",\n",
    "#                    \"ref_type\":                \"category\",\n",
    "                   \"ref_hash\":                \"object\",\n",
    "#                    \"click_hash\":             \"category\",\n",
    "                   \"attributed\":               \"bool\",\n",
    "                   \"implicit\":                 \"bool\",\n",
    "#                    \"device_countrycode\":      \"category\",\n",
    "                   \"device_brand\":          \"category\",\n",
    "                   \"device_model\":          \"category\",\n",
    "                   \"session_user_agent\":     \"category\",\n",
    "#                    \"user_agent\":             \"category\",\n",
    "#                    \"event_uuid\":             \"category\",\n",
    "#                    \"kind\":                   \"category\",\n",
    "#                    \"wifi\":                   \"category\",\n",
    "#                    \"trans_id\":               \"category\",\n",
    "#                    \"ip_address\":              \"category\",\n",
    "                   \"device_language\":       \"category\"}\n",
    "\n",
    "def load_installs(users=get_target_ids(), days=all_days):\n",
    "    \"\"\"\n",
    "    load installs csv, only users and days specified in users and days lists.\n",
    "    If lists left empty, consider whole set of users and days respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_installs = pd.read_csv('../data/installs.csv', engine='c', dtype=installs_dtypes, parse_dates=['created'], usecols=installs_cols)\n",
    "    \n",
    "    def load_condition(df):\n",
    "        return df['ref_hash'].isin(users) & df['created'].dt.day.isin(days)\n",
    "    \n",
    "    df = df_installs.loc[load_condition(df_installs)].copy()\n",
    "    \n",
    "    df.rename(columns={'created':'date'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "events_cols = ['date','ref_hash','application_id','attributed','device_model','ip_address']\n",
    "\n",
    "events_dtypes = {\n",
    "#     \"index\":                   \"category\",\n",
    "#                  \"event_id\":                \"category\",\n",
    "#                  \"ref_type\":                \"category\",\n",
    "                 \"ref_hash\":                \"category\",\n",
    "                 \"application_id\":          \"category\",\n",
    "                 \"attributed\":               \"bool\",\n",
    "#                  \"device_countrycode\":      \"category\",\n",
    "#                  \"device_os_version\":     \"category\",\n",
    "#                  \"device_brand\":          \"category\",\n",
    "                 \"device_model\":          \"category\",\n",
    "#                  \"device_city\":           \"category\",\n",
    "#                  \"session_user_agent\":    \"category\",\n",
    "#                  \"trans_id\":               \"category\",\n",
    "#                  \"user_agent\":            \"category\",\n",
    "#                  \"event_uuid\":             \"category\",\n",
    "#                  \"carrier\":               \"category\",\n",
    "#                  \"kind\":                  \"category\",\n",
    "#                  \"device_os\":             \"category\",\n",
    "#                  \"wifi\":                     \"bool\",\n",
    "#                  \"connection_type\":        \"category\",\n",
    "                 \"ip_address\":              \"category\",\n",
    "#                  \"device_language\":       \"category\"\n",
    "}\n",
    "\n",
    "def load_events(users=get_target_ids(), days=all_days):\n",
    "    \"\"\"\n",
    "    load events csv, only users and days specified in users and days lists.\n",
    "    If lists left empty, consider whole set of users and days respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    iter_events = pd.read_csv('../data/events.csv', engine='c', dtype=events_dtypes, parse_dates=['date'], chunksize=10000, usecols=events_cols)\n",
    "    \n",
    "    def load_condition(chunk):\n",
    "        return chunk['ref_hash'].isin(users) & chunk['date'].dt.day.isin(days)\n",
    "    \n",
    "    df = pd.concat(chunk.loc[load_condition(chunk)] for chunk in iter_events)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "essential_load_on_startup"
    ]
   },
   "outputs": [],
   "source": [
    "auction_cols = ['date','device_id']\n",
    "\n",
    "auctions_dtypes = {'device_id':'category',\n",
    "#                  'ref_type_id':'category',\n",
    "#                  'source_id':'category'\n",
    "                  }\n",
    "\n",
    "def load_auctions(users=get_target_ids(), days=all_days):\n",
    "    \"\"\"\n",
    "    load auctions csv, only users and days specified in users and days lists.\n",
    "    If lists left empty, consider whole set of users and days respectively.\n",
    "    \"\"\"\n",
    "    iter_auctions = pd.read_csv('../data/auctions.csv', engine='c', dtype=auctions_dtypes, parse_dates=['date'], chunksize=10000, usecols=auction_cols)\n",
    "    def load_condition(chunk):\n",
    "        return chunk['device_id'].isin(users) & chunk['date'].dt.day.isin(days)\n",
    "    df = pd.concat(chunk.loc[load_condition(chunk)] for chunk in iter_auctions)\n",
    "    \n",
    "    df.rename(columns={'device_id':'ref_hash'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudo resumen de cosas utiles para aplicar\n",
    "Para survival analysis se necesitan dos cosas:\n",
    "- an array of durations\n",
    "- either a boolean or binary array representing whether the “death” was observed or not (alternatively an individual can be censored)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un vistazo sobre los dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_clicks(get_target_ids_chunk(1), all_days[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>date</th>\n",
       "      <th>ref_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11899</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-20 04:23:39.214</td>\n",
       "      <td>1102680423242413676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11922</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-20 04:30:28.785</td>\n",
       "      <td>1102680423242413676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25085</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 16:55:31.227</td>\n",
       "      <td>1102680423242413676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61291</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-20 19:53:18.984</td>\n",
       "      <td>1058525390691423513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63806</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-19 12:46:43.763</td>\n",
       "      <td>1058525390691423513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_id                    date             ref_hash\n",
       "11899         1 2019-04-20 04:23:39.214  1102680423242413676\n",
       "11922         1 2019-04-20 04:30:28.785  1102680423242413676\n",
       "25085         1 2019-04-18 16:55:31.227  1102680423242413676\n",
       "61291         1 2019-04-20 19:53:18.984  1058525390691423513\n",
       "63806         1 2019-04-19 12:46:43.763  1058525390691423513"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_installs(get_target_ids_chunk(1), all_days[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>application_id</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>attributed</th>\n",
       "      <th>implicit</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>session_user_agent</th>\n",
       "      <th>device_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7016</th>\n",
       "      <td>2019-04-19 02:37:34.033</td>\n",
       "      <td>14</td>\n",
       "      <td>1128814228344083814</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.208834667126999e+18</td>\n",
       "      <td>4.445013666528814e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3013777759776993e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>2019-04-19 02:37:34.101</td>\n",
       "      <td>14</td>\n",
       "      <td>1128814228344083814</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.208834667126999e+18</td>\n",
       "      <td>4.445013666528814e+18</td>\n",
       "      <td>HasOffers Mobile AppTracking v1.0</td>\n",
       "      <td>3.3013777759776993e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28381</th>\n",
       "      <td>2019-04-18 22:23:29.656</td>\n",
       "      <td>49</td>\n",
       "      <td>1048782984015604883</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.794880020077885e+18</td>\n",
       "      <td>http-kit/2.0</td>\n",
       "      <td>8.441417429938962e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48676</th>\n",
       "      <td>2019-04-20 12:35:20.625</td>\n",
       "      <td>77</td>\n",
       "      <td>1054881396892383323</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3445980799392305e+18</td>\n",
       "      <td>adjust.com</td>\n",
       "      <td>4.060929664968129e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50673</th>\n",
       "      <td>2019-04-20 02:31:26.269</td>\n",
       "      <td>78</td>\n",
       "      <td>1010265377387765028</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.115025880051902e+18</td>\n",
       "      <td>1.670346184923358e+18</td>\n",
       "      <td>http-kit/2.0</td>\n",
       "      <td>6.977049253562486e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date application_id             ref_hash  attributed  \\\n",
       "7016  2019-04-19 02:37:34.033             14  1128814228344083814       False   \n",
       "7022  2019-04-19 02:37:34.101             14  1128814228344083814       False   \n",
       "28381 2019-04-18 22:23:29.656             49  1048782984015604883       False   \n",
       "48676 2019-04-20 12:35:20.625             77  1054881396892383323       False   \n",
       "50673 2019-04-20 02:31:26.269             78  1010265377387765028       False   \n",
       "\n",
       "       implicit           device_brand            device_model  \\\n",
       "7016      False  2.208834667126999e+18   4.445013666528814e+18   \n",
       "7022       True  2.208834667126999e+18   4.445013666528814e+18   \n",
       "28381      True                    NaN   6.794880020077885e+18   \n",
       "48676     False                    NaN  1.3445980799392305e+18   \n",
       "50673     False  6.115025880051902e+18   1.670346184923358e+18   \n",
       "\n",
       "                      session_user_agent         device_language  \n",
       "7016                                 NaN  3.3013777759776993e+18  \n",
       "7022   HasOffers Mobile AppTracking v1.0  3.3013777759776993e+18  \n",
       "28381                       http-kit/2.0   8.441417429938962e+18  \n",
       "48676                         adjust.com   4.060929664968129e+18  \n",
       "50673                       http-kit/2.0   6.977049253562486e+18  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_events(get_target_ids_chunk(1), all_days[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>application_id</th>\n",
       "      <th>attributed</th>\n",
       "      <th>device_model</th>\n",
       "      <th>ip_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170519</th>\n",
       "      <td>2019-04-18 03:43:09.185</td>\n",
       "      <td>1106971792117053344</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>5.186986602616849e+18</td>\n",
       "      <td>7209709704711395089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170521</th>\n",
       "      <td>2019-04-18 03:43:25.436</td>\n",
       "      <td>1106971792117053344</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>5.186986602616849e+18</td>\n",
       "      <td>7209709704711395089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170525</th>\n",
       "      <td>2019-04-18 03:43:21.320</td>\n",
       "      <td>1106971792117053344</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>5.186986602616849e+18</td>\n",
       "      <td>7209709704711395089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170529</th>\n",
       "      <td>2019-04-18 03:43:08.996</td>\n",
       "      <td>1106971792117053344</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>5.186986602616849e+18</td>\n",
       "      <td>7209709704711395089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171835</th>\n",
       "      <td>2019-04-19 17:01:38.181</td>\n",
       "      <td>1117811498061299916</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0574023248014715e+18</td>\n",
       "      <td>3382054713307838865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date             ref_hash application_id  \\\n",
       "170519 2019-04-18 03:43:09.185  1106971792117053344             65   \n",
       "170521 2019-04-18 03:43:25.436  1106971792117053344             65   \n",
       "170525 2019-04-18 03:43:21.320  1106971792117053344             65   \n",
       "170529 2019-04-18 03:43:08.996  1106971792117053344             65   \n",
       "171835 2019-04-19 17:01:38.181  1117811498061299916             65   \n",
       "\n",
       "        attributed            device_model           ip_address  \n",
       "170519       False   5.186986602616849e+18  7209709704711395089  \n",
       "170521       False   5.186986602616849e+18  7209709704711395089  \n",
       "170525       False   5.186986602616849e+18  7209709704711395089  \n",
       "170529       False   5.186986602616849e+18  7209709704711395089  \n",
       "171835       False  3.0574023248014715e+18  3382054713307838865  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_auctions(get_target_ids_chunk(1), all_days[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>ref_type_id</th>\n",
       "      <th>source_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289649</th>\n",
       "      <td>2019-04-18 19:58:47.826462</td>\n",
       "      <td>1114026657194419748</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317697</th>\n",
       "      <td>2019-04-18 23:34:28.216676</td>\n",
       "      <td>1102680423242413676</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317713</th>\n",
       "      <td>2019-04-18 23:34:36.035822</td>\n",
       "      <td>1102680423242413676</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317978</th>\n",
       "      <td>2019-04-18 23:42:35.347774</td>\n",
       "      <td>1102680423242413676</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318297</th>\n",
       "      <td>2019-04-18 23:44:54.822177</td>\n",
       "      <td>1102680423242413676</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date             ref_hash ref_type_id source_id\n",
       "289649 2019-04-18 19:58:47.826462  1114026657194419748           1         0\n",
       "317697 2019-04-18 23:34:28.216676  1102680423242413676           1         1\n",
       "317713 2019-04-18 23:34:36.035822  1102680423242413676           1         1\n",
       "317978 2019-04-18 23:42:35.347774  1102680423242413676           1         1\n",
       "318297 2019-04-18 23:44:54.822177  1102680423242413676           1         1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML: Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Approach 1: mean value per device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions = load_auctions()\n",
    "\n",
    "df_auctions2 = process_time_diffs(df_auctions)\n",
    "\n",
    "current_predictions = df_auctions2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()\n",
    "\n",
    "target = store_predictions(target_df=target, new_values=current_predictions, value_column_name='diff_in_sec', suffix='_st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_auctions\n",
    "del df_auctions2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs = load_installs()\n",
    "\n",
    "df_installs2 = process_time_diffs(df_installs)\n",
    "\n",
    "current_predictions = df_installs2[['ref_hash','diff_in_sec']].groupby('ref_hash', as_index=False).mean()\n",
    "\n",
    "target = store_predictions(target_df=target, new_values=current_predictions, value_column_name='diff_in_sec', suffix='_sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_installs\n",
    "del df_installs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(target, description=\"por cada grupo, avg. de los tiempos entre cada registro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Approach 1: mean value per device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Approach 2: mean value per device taking time from one common start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions = load_auctions(days=get_n_3_days(1))\n",
    "\n",
    "df_auctions2 = process_time_diffs_vs_min_day(df_auctions)\n",
    "\n",
    "current_predictions = df_auctions2.groupby('ref_hash', as_index=False)[['diff_in_sec']].mean()\n",
    "\n",
    "target = store_predictions(target_df=target, new_values=current_predictions, value_column_name='diff_in_sec', suffix='_st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_auctions\n",
    "del df_auctions2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installs = load_installs(days=get_n_3_days(1))\n",
    "\n",
    "df_installs2 = process_time_diffs_vs_min_day(df_installs)\n",
    "\n",
    "current_predictions = df_installs2[['ref_hash','diff_in_sec']].groupby('ref_hash', as_index=False).mean()\n",
    "\n",
    "target = store_predictions(target_df=target, new_values=current_predictions, value_column_name='diff_in_sec', suffix='_sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_installs\n",
    "del df_installs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(target, description=\"por cada grupo, avg. de los tiempos tomados a partir del primer dia de los elegidos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## End of Approach 2: mean value per device taking time from one common start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Approach 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define current users/days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_users = get_target_ids()\n",
    "current_days = get_n_3_days(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = load_clicks(current_users, current_days)\n",
    "df_installs = load_installs(current_users, current_days)\n",
    "df_events = load_events(current_users, current_days)\n",
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.727891\n",
      "2.071247\n",
      "6.177316\n",
      "25.952431\n"
     ]
    }
   ],
   "source": [
    "print(df_clicks.memory_usage(deep=True).sum()/1e6)\n",
    "print(df_installs.memory_usage(deep=True).sum()/1e6)\n",
    "print(df_events.memory_usage(deep=True).sum()/1e6)\n",
    "print(df_auctions.memory_usage(deep=True).sum()/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate time diffs per ref hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = process_time_diffs(df_clicks)\n",
    "df_installs = process_time_diffs(df_installs)\n",
    "df_events = process_time_diffs(df_events)\n",
    "df_auctions = process_time_diffs(df_auctions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append 'em!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_source_col(df_clicks, \"clicks\")\n",
    "set_source_col(df_installs, \"installs\")\n",
    "set_source_col(df_events, \"events\")\n",
    "set_source_col(df_auctions, \"auctions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = df_clicks.append(df_installs, sort=False).append(df_events, sort=False).append(df_auctions, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended.diff_in_sec = appended.diff_in_sec.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "976372"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = fill_all_nans(appended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = set_observed_column(appended, \"auctions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185944, 15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>date</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>source_csv</th>\n",
       "      <th>application_id</th>\n",
       "      <th>attributed</th>\n",
       "      <th>implicit</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>session_user_agent</th>\n",
       "      <th>device_language</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>diff_in_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 14:21:13.536</td>\n",
       "      <td>7425652559562776089</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10276</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 04:26:38.599</td>\n",
       "      <td>9001894065986101363</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10279</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-18 04:31:18.746</td>\n",
       "      <td>7906060474484893014</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10296</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 04:26:56.196</td>\n",
       "      <td>4164621178487252757</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10297</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 04:27:00.527</td>\n",
       "      <td>4164621178487252757</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_id                    date             ref_hash source_csv  \\\n",
       "1001          1 2019-04-18 14:21:13.536  7425652559562776089     clicks   \n",
       "10276         1 2019-04-18 04:26:38.599  9001894065986101363     clicks   \n",
       "10279         3 2019-04-18 04:31:18.746  7906060474484893014     clicks   \n",
       "10296         1 2019-04-18 04:26:56.196  4164621178487252757     clicks   \n",
       "10297         1 2019-04-18 04:27:00.527  4164621178487252757     clicks   \n",
       "\n",
       "      application_id attributed implicit device_brand device_model  \\\n",
       "1001             NaN        NaN      NaN          NaN          NaN   \n",
       "10276            NaN        NaN      NaN          NaN          NaN   \n",
       "10279            NaN        NaN      NaN          NaN          NaN   \n",
       "10296            NaN        NaN      NaN          NaN          NaN   \n",
       "10297            NaN        NaN      NaN          NaN          NaN   \n",
       "\n",
       "      session_user_agent device_language ip_address  diff_in_sec  \n",
       "1001                 NaN             NaN        NaN          NaN  \n",
       "10276                NaN             NaN        NaN          NaN  \n",
       "10279                NaN             NaN        NaN          NaN  \n",
       "10296                NaN             NaN        NaN          NaN  \n",
       "10297                NaN             NaN        NaN          NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = appended.drop(['diff_in_sec','observed','date'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct y_train array of tuples as needed.\n",
    "# To understand this, see: https://scikit-survival.readthedocs.io/en/latest/generated/sksurv.util.Surv.html#sksurv.util.Surv.from_dataframe\n",
    "from sksurv.util import Surv\n",
    "\n",
    "helper = Surv()\n",
    "\n",
    "y_train = helper.from_dataframe('observed','diff_in_sec', appended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.preprocessing import OneHotEncoder\n",
    "\n",
    "X_train_numeric = OneHotEncoder().fit_transform(X_train)\n",
    "X_train_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "\n",
    "estimator = CoxPHSurvivalAnalysis(alpha=0.001)\n",
    "estimator.fit(X_train_numeric, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(estimator.coef_, index=X_train_numeric.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "El approach con `scikit-survival` fue abandonado debido a las incesantes complicaciones debidas a la pobre implementacion de la libreria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## End of Approach 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Approach 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define current users/days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_users = get_target_ids()\n",
    "current_days = get_n_3_days(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = load_clicks(current_users, current_days)\n",
    "df_installs = load_installs(current_users, current_days)\n",
    "df_events = load_events(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions = load_auctions(current_users, current_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.727891\n",
      "2.071247\n",
      "6.177316\n",
      "15.009189\n"
     ]
    }
   ],
   "source": [
    "print(df_clicks.memory_usage(deep=True).sum()/1e6)\n",
    "print(df_installs.memory_usage(deep=True).sum()/1e6)\n",
    "print(df_events.memory_usage(deep=True).sum()/1e6)\n",
    "print(df_auctions.memory_usage(deep=True).sum()/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate time diffs per ref hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_auctions = process_time_diffs(df_auctions)\n",
    "\n",
    "# df_auctions.drop('diff_in_sec',axis='columns',inplace=True)\n",
    "\n",
    "# df_auctions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append 'em!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_source_col(df_clicks, \"clicks\")\n",
    "set_source_col(df_installs, \"installs\")\n",
    "set_source_col(df_events, \"events\")\n",
    "set_source_col(df_auctions, \"auctions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = df_clicks.append(df_installs, sort=False).append(df_events, sort=False).append(df_auctions, sort=False)\n",
    "\n",
    "# appended.diff_in_sec = appended.diff_in_sec.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>date</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>source_csv</th>\n",
       "      <th>application_id</th>\n",
       "      <th>attributed</th>\n",
       "      <th>implicit</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>session_user_agent</th>\n",
       "      <th>device_language</th>\n",
       "      <th>ip_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 14:21:13.536</td>\n",
       "      <td>7425652559562776089</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10276</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 04:26:38.599</td>\n",
       "      <td>9001894065986101363</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10279</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-18 04:31:18.746</td>\n",
       "      <td>7906060474484893014</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10296</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 04:26:56.196</td>\n",
       "      <td>4164621178487252757</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10297</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-18 04:27:00.527</td>\n",
       "      <td>4164621178487252757</td>\n",
       "      <td>clicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_id                    date             ref_hash source_csv  \\\n",
       "1001          1 2019-04-18 14:21:13.536  7425652559562776089     clicks   \n",
       "10276         1 2019-04-18 04:26:38.599  9001894065986101363     clicks   \n",
       "10279         3 2019-04-18 04:31:18.746  7906060474484893014     clicks   \n",
       "10296         1 2019-04-18 04:26:56.196  4164621178487252757     clicks   \n",
       "10297         1 2019-04-18 04:27:00.527  4164621178487252757     clicks   \n",
       "\n",
       "      application_id attributed implicit device_brand device_model  \\\n",
       "1001             NaN        NaN      NaN          NaN          NaN   \n",
       "10276            NaN        NaN      NaN          NaN          NaN   \n",
       "10279            NaN        NaN      NaN          NaN          NaN   \n",
       "10296            NaN        NaN      NaN          NaN          NaN   \n",
       "10297            NaN        NaN      NaN          NaN          NaN   \n",
       "\n",
       "      session_user_agent device_language ip_address  \n",
       "1001                 NaN             NaN        NaN  \n",
       "10276                NaN             NaN        NaN  \n",
       "10279                NaN             NaN        NaN  \n",
       "10296                NaN             NaN        NaN  \n",
       "10297                NaN             NaN        NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = get_time_to_event_of_interest(appended, \"auctions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = appended.loc[appended['source_csv'] != \"auctions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdf2 = pd.get_dummies(data=asdf.drop(['date','diff_in_sec','ref_hash'], axis='columns'), dummy_na=True)\n",
    "# asdf2[['date','diff_in_sec','ref_hash']] = asdf[['date','diff_in_sec','ref_hash']]\n",
    "\n",
    "# asdf2.attributed.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>date</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>source_csv</th>\n",
       "      <th>application_id</th>\n",
       "      <th>attributed</th>\n",
       "      <th>implicit</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>session_user_agent</th>\n",
       "      <th>device_language</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>diff_in_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4623047</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-20 21:17:43.910</td>\n",
       "      <td>1000169251625791246</td>\n",
       "      <td>events</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8054562877343293e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8443069915943166930</td>\n",
       "      <td>183861.9991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4025197</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-20 21:17:53.248</td>\n",
       "      <td>1000169251625791246</td>\n",
       "      <td>events</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8054562877343293e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8443069915943166930</td>\n",
       "      <td>183871.3371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193009</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-20 23:41:55.279</td>\n",
       "      <td>1000169251625791246</td>\n",
       "      <td>events</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8054562877343293e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9169560242611875077</td>\n",
       "      <td>192513.3681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193107</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-20 23:41:55.996</td>\n",
       "      <td>1000169251625791246</td>\n",
       "      <td>events</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8054562877343293e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9169560242611875077</td>\n",
       "      <td>192514.0851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461154</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-20 23:44:35.185</td>\n",
       "      <td>1000169251625791246</td>\n",
       "      <td>events</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8054562877343293e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9169560242611875077</td>\n",
       "      <td>192673.2741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_id                    date             ref_hash source_csv  \\\n",
       "4623047       NaN 2019-04-20 21:17:43.910  1000169251625791246     events   \n",
       "4025197       NaN 2019-04-20 21:17:53.248  1000169251625791246     events   \n",
       "3193009       NaN 2019-04-20 23:41:55.279  1000169251625791246     events   \n",
       "3193107       NaN 2019-04-20 23:41:55.996  1000169251625791246     events   \n",
       "4461154       NaN 2019-04-20 23:44:35.185  1000169251625791246     events   \n",
       "\n",
       "        application_id attributed implicit device_brand  \\\n",
       "4623047             21      False      NaN          NaN   \n",
       "4025197             21      False      NaN          NaN   \n",
       "3193009             21      False      NaN          NaN   \n",
       "3193107             21      False      NaN          NaN   \n",
       "4461154             21      False      NaN          NaN   \n",
       "\n",
       "                   device_model session_user_agent device_language  \\\n",
       "4623047  1.8054562877343293e+18                NaN             NaN   \n",
       "4025197  1.8054562877343293e+18                NaN             NaN   \n",
       "3193009  1.8054562877343293e+18                NaN             NaN   \n",
       "3193107  1.8054562877343293e+18                NaN             NaN   \n",
       "4461154  1.8054562877343293e+18                NaN             NaN   \n",
       "\n",
       "                  ip_address  diff_in_sec  \n",
       "4623047  8443069915943166930  183861.9991  \n",
       "4025197  8443069915943166930  183871.3371  \n",
       "3193009  9169560242611875077  192513.3681  \n",
       "3193107  9169560242611875077  192514.0851  \n",
       "4461154  9169560242611875077  192673.2741  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
